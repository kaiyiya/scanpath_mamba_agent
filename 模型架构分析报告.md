# Mamba-Adaptive扫描路径生成模型架构分析报告

## 一、模型概述

### 1.1 研究背景
本模型针对360度全景图像的扫描路径（scanpath）生成任务，结合了Mamba状态空间模型和AdaptiveNN的Focus机制，实现了长期依赖建模和自适应特征提取。

### 1.2 核心创新点
1. **Mamba序列建模**：使用状态空间模型（SSM）实现长期依赖，参数量为O(1)
2. **双流特征提取**：Glance（全局）+ Focus（局部高分辨率）
3. **动态特征更新**：根据注视点位置动态更新全局特征表示
4. **VAE概率建模**：防止过拟合，增加预测多样性
5. **360度图像特殊处理**：考虑等距圆柱投影的周期性边界

---

## 二、模型架构详解

### 2.1 整体架构

```
输入图像 (B, 3, 256, 512)
    ↓
[Glance网络] → 全局特征 (B, 196, 384)
    ↓
[序列生成循环] (30步)
    ├─ 根据当前位置crop局部patch
    ├─ [Focus网络] → 局部特征 (B, 196, 384)
    ├─ [特征更新] → 更新全局特征
    ├─ [Mamba] → 序列状态建模
    ├─ [VAE] → 概率位置预测
    └─ 输出下一位置 (B, 2)
    ↓
完整扫描路径 (B, 30, 2)
```

### 2.2 核心组件

#### 2.2.1 Glance网络（全局特征提取）

**位置**：`models/improved_model_v5.py` → `OptimizedSphereGlanceNet`

**架构**：
```
输入: (B, 3, 256, 512) - 360度等距圆柱投影图像
    ↓
SphereConv2D(3→64, stride=2) + BN + LeakyReLU
    ↓
SphereConv2D(64→128, stride=2) + BN + LeakyReLU + ECA注意力
    ↓
SphereConv2D(128→256, stride=2) + BN + LeakyReLU
    ↓
SphereConv2D(256→512, stride=2) + BN + LeakyReLU + ECA注意力
    ↓
AdaptiveAvgPool2d(14×14) → (B, 512, 14, 14)
    ↓
Reshape → (B, 196, 512)
    ↓
Linear(512→384) → (B, 196, 384)
```

**关键特性**：
- **球面卷积（SphereConv2D）**：专门处理360度图像的球面几何特性
  - 考虑等距圆柱投影的左右边界连续性
  - 使用grid_sample实现球面采样
  - 支持缓存机制优化性能
- **特征图尺寸**：14×14=196个空间位置，保留更多空间信息
- **ECA注意力**：高效通道注意力，在关键层使用

#### 2.2.2 Focus网络（局部特征提取）

**位置**：`models/improved_model_v5.py` → `OptimizedFocusNet`

**架构**：
```
输入: (B, 3, 224, 224) - 局部patch
    ↓
Conv2d(3→64, 7×7, stride=2) + BN + ReLU + MaxPool
    ↓
Conv2d(64→128, 3×3, stride=2) + BN + ReLU
    ↓
Conv2d(128→256, 3×3, stride=2) + BN + ReLU
    ↓
Conv2d(256→512, 3×3, stride=2) + BN + ReLU + ECA注意力
    ↓
AdaptiveAvgPool2d(14×14) → (B, 512, 14, 14)
    ↓
Reshape → (B, 196, 512)
    ↓
Linear(512→384) → (B, 196, 384)
```

**关键特性**：
- **高分辨率处理**：224×224的局部patch，提取细节特征
- **自适应池化**：输出与Glance网络相同的空间分辨率（14×14）

#### 2.2.3 Mamba序列建模

**位置**：`models/mamba_adaptive_scanpath.py` → `MambaAdaptiveScanpathGenerator`

**Mamba参数**：
- `d_model=384`：模型维度
- `d_state=256`：SSM状态维度
- `d_conv=4`：局部卷积宽度
- `expand=2`：扩展因子

**工作原理**：
1. **状态空间模型（SSM）**：
   - 将序列建模问题转化为状态空间方程
   - 使用选择性机制（selective mechanism）实现长期依赖
   - 参数量为O(1)，而非Transformer的O(n²)

2. **序列累积**：
   ```python
   # 累积历史特征序列（最多10步）
   recent_history = history_features[-min(10, t + 1):]
   history_seq = torch.stack(recent_history, dim=0)  # (T, B, C)
   history_seq = history_seq.transpose(0, 1)  # (B, T, C)
   h_t = self.mamba(history_seq)  # (B, T, C)
   h_t = h_t[:, -1:, :]  # 只取最后一个时间步 (B, 1, C)
   ```

3. **优势**：
   - 线性复杂度：O(n)而非O(n²)
   - 长期依赖：状态空间可以保持长期记忆
   - 参数效率：共享参数，减少过拟合

#### 2.2.4 特征更新机制

**位置**：`models/feature_update_v2.py` → `CrossAttentionFeatureUpdate`

**更新流程**：
```
全局特征 (B, 196, 384)
    ↓
[空间权重计算] → 基于当前位置的高斯权重 (B, 196, 1)
    ↓
局部特征聚合 → (B, 1, 384)
    ↓
[门控融合]
    ├─ gate = sigmoid(Linear([global; update_signal]))
    └─ updated = gate * update_signal + (1-gate) * global
    ↓
更新后的全局特征 (B, 196, 384)
```

**关键特性**：
- **空间权重**：考虑360度图像的wrap around特性
  ```python
  # X方向距离（考虑wrap around）
  x_dist = torch.abs(grid_positions[:, :, 0:1] - pos_expanded[:, :, 0:1])
  x_dist = torch.min(x_dist, 1.0 - x_dist)  # wrap around
  ```
- **门控机制**：自适应控制更新强度

#### 2.2.5 VAE概率建模

**位置**：`models/mamba_adaptive_scanpath.py` → `MambaAdaptiveScanpathGenerator`

**架构**：
```
Mamba输出 + 当前特征 + 位置信息
    ↓
[编码器]
    ├─ latent_mu → 均值 (B, 192)
    └─ latent_logvar → 对数方差 (B, 192)
    ↓
[重参数化] z = mu + eps * sigma * temperature
    ↓
[解码器] position_decoder
    ├─ Linear(192+4 → 192) → LayerNorm → GELU
    ├─ Linear(192 → 96) → LayerNorm → GELU
    ├─ Linear(96 → 48) → LayerNorm → GELU
    └─ Linear(48 → 2) → Tanh → [0, 1]
    ↓
预测位置 (B, 2)
```

**关键特性**：
- **概率建模**：通过KL散度正则化防止过拟合
- **温度采样**：推理时可通过temperature控制多样性
- **位置融合**：融合当前位置和历史位置信息

#### 2.2.6 位置编码

**位置**：`models/mamba_adaptive_scanpath.py` → `position_encoder`

**360度周期性编码**：
```python
# X坐标（经度）：周期性编码
pos_x_periodic = torch.stack([
    torch.sin(2 * torch.pi * prev_pos[:, 0]),  # sin(2πx)
    torch.cos(2 * torch.pi * prev_pos[:, 0])   # cos(2πx)
], dim=-1)  # (B, 2)

# Y坐标（纬度）：直接使用（非周期性）
pos_y = prev_pos[:, 1:2]  # (B, 1)

# 组合编码
pos_encoded_input = torch.cat([pos_x_periodic, pos_y, bias], dim=-1)  # (B, 4)
pos_encoded = self.position_encoder(pos_encoded_input)  # (B, 384)
```

**关键特性**：
- **周期性编码**：X坐标使用sin/cos编码，捕获x=0和x=1的连续性
- **非周期性编码**：Y坐标直接使用，因为纬度不是周期性的

#### 2.2.7 Y方向注意力

**位置**：`models/y_attention.py` → `YDirectionAttention`

**目的**：鼓励Y方向（纬度）的多样性，避免预测聚集在图像中心

**架构**：
```
当前特征 (B, 384)
    ↓
投影 → (B, 192)
    ↓
历史Y位置 (B, T) → 位置编码 → (B, T, 192)
    ↓
MultiheadAttention(query=当前, key/value=历史)
    ↓
MLP → Tanh → Y方向偏置 (B, 1)
    ↓
添加到预测位置的Y坐标
```

---

## 三、训练策略

### 3.1 损失函数设计

**位置**：`train_mamba_adaptive.py`

#### 3.1.1 重构损失（Reconstruction Loss）
```python
reconstruction_loss = MSE(predicted_scanpaths, true_scanpaths)
```
- **权重**：2.0-2.5（随训练动态调整）
- **作用**：确保预测路径与真实路径对齐

#### 3.1.2 KL散度正则化
```python
kl_loss = -0.5 * sum(1 + logvar - mu² - exp(logvar))
kl_loss = kl_loss / (batch_size * seq_len)
```
- **权重**：0.003
- **作用**：防止VAE过拟合，增加预测多样性

#### 3.1.3 空间覆盖损失（Spatial Coverage Loss）
```python
# 覆盖范围约束
coverage_x = mean((0.3 - pred_range_x)²)
coverage_y = mean((0.25 - pred_range_y)²)

# 多样性约束
diversity_x = mean((0.015 - pred_var_x)²)
diversity_y = mean((0.025 - pred_var_y)²)

# Y方向中心聚集惩罚
y_bias_penalty = mean((|y_mean - 0.5| - 0.05)²)
```
- **权重**：2.0-2.5
- **作用**：鼓励模型探索整个图像空间，避免聚集

#### 3.1.4 轨迹平滑损失（Trajectory Smoothness Loss）
```python
# 步长匹配
step_loss = MSE(pred_steps, true_steps)

# 跳跃惩罚
jump_loss = mean((pred_steps - 0.2)²)

# 加速度约束
accel_loss = MSE(pred_accel, true_accel)
```
- **权重**：0.3
- **作用**：保持轨迹平滑，符合眼动规律

#### 3.1.5 方向一致性损失（Direction Consistency Loss）
```python
# 方向变化
direction_loss = MSE(pred_dir_diffs, true_dir_diffs)

# 方向连续性
continuity_loss = MSE(pred_similarity, true_similarity)
```
- **权重**：0.3
- **作用**：保持方向一致性

#### 3.1.6 序列对齐损失（Sequence Alignment Loss）
```python
# 加权点对点距离
point_distances = norm(pred - true, dim=-1)  # (B, T)
weights = [3.0, 2.5, 2.0, 1.5, 1.3, 1.2]  # 前5/5-10/10-15/15-20/20-25/25-30步
alignment_loss = mean(point_distances * weights)
```
- **权重**：1.5-2.0
- **作用**：约束所有30步的对齐，前几步权重更高

#### 3.1.7 边界约束
```python
boundary_penalty = mean(
    (pred < 0.02) * (0.02 - pred)² +
    (pred > 0.98) * (pred - 0.98)²
)
```
- **权重**：0.2
- **作用**：约束预测位置在有效范围内

### 3.2 Teacher Forcing策略

**位置**：`train_mamba_adaptive.py` → `compute_teacher_forcing_ratio`

**指数衰减策略**：
```python
initial_ratio = 0.8
final_ratio = 0.2
decay_epochs = 50

# 指数衰减
k = -log(final_ratio / initial_ratio) / decay_epochs
base_ratio = initial_ratio * exp(-k * epoch)

# 前几步额外加权
if step_idx < 3:
    ratio = min(base_ratio + 0.15, 0.95)
elif step_idx < 6:
    ratio = min(base_ratio + 0.08, 0.90)
elif step_idx < 10:
    ratio = min(base_ratio + 0.03, 0.85)
```

**关键特性**：
- **指数衰减**：从0.8逐渐降到0.2
- **前几步加权**：前3步、3-6步、6-10步分别额外加权
- **平滑过渡**：避免突然从teacher forcing切换到自由生成

### 3.3 优化器配置

```python
optimizer = AdamW(
    lr=2e-4,
    weight_decay=2e-3
)

scheduler = CosineAnnealingLR(
    T_max=50,
    eta_min=2e-6  # 最小学习率为初始的1%
)
```

### 3.4 自动停止机制

**位置**：`models/mamba_adaptive_scanpath.py` → `stop_classifier`

**架构**：
```
当前特征 (B, 384)
    ↓
Linear(384 → 192) → LayerNorm → GELU → Dropout
    ↓
Linear(192 → 1) → Sigmoid
    ↓
继续概率 [0, 1]
```

**停止条件**：
- `continue_prob < stop_threshold`（默认0.5）
- `t >= min_steps`（默认5步）
- 推理时启用，训练时禁用

---

## 四、360度图像特殊处理

### 4.1 Wrap Around处理

**位置**：`models/mamba_adaptive_scanpath.py` → `get_img_patches`

**X坐标（经度）wrap around**：
```python
# 计算patch中心
x_center = positions[i, 1] * W - patch_size / 2

# Wrap around处理
x_start = int(x_center) % W

# 如果跨越右边界
if x_start + patch_size > W:
    right_part = images[:, :, y_start:y_start+patch_size, x_start:]
    left_part = images[:, :, y_start:y_start+patch_size, :(x_start+patch_size-W)]
    patch = torch.cat([right_part, left_part], dim=3)
```

**Y坐标（纬度）clamp**：
```python
# Y坐标不是周期性的，使用clamp
y_start = int(torch.clamp(torch.tensor(y_center), 0, H - patch_size).item())
```

### 4.2 位置预测的Wrap Around

**位置**：`models/mamba_adaptive_scanpath.py` → `forward`

```python
# X坐标wrap around
pos_t_x_raw = pos_t[:, 0]
pos_t_x = pos_t_x_raw % 1.0  # wrap around到[0, 1]

# 处理边界情况
pos_t_x = torch.where(
    pos_t_x < 0.02,
    pos_t_x + 0.98,  # 从左边wrap到右边
    torch.where(
        pos_t_x > 0.98,
        pos_t_x - 0.98,  # 从右边wrap到左边
        pos_t_x
    )
)
pos_t_x = torch.clamp(pos_t_x, 0.02, 0.98)

# Y坐标clamp（非周期性）
pos_t_y = torch.clamp(pos_t[:, 1], 0.02, 0.98)
```

---

## 五、数据流程

### 5.1 数据加载

**位置**：`data/dataset.py` → `Salient360ScanpathDataset`

**数据格式**：
- **图像**：`(3, 256, 512)` - RGB，360度等距圆柱投影
- **扫描路径**：`(30, 2)` - 归一化坐标[0, 1]，格式为(x, y)
- **数据集**：Salient360 H+HE合并数据集

**数据增强**：
1. **水平翻转**（50%概率）：
   ```python
   image = torch.flip(image, dims=[2])
   scanpath[:, 0] = 1.0 - scanpath[:, 0]
   ```

2. **水平循环移位**（50%概率）：
   ```python
   shift_ratio = random()
   image = torch.roll(image, shifts=int(W * shift_ratio), dims=2)
   scanpath[:, 0] = (scanpath[:, 0] + shift_ratio) % 1.0
   ```

### 5.2 前向传播流程

```
1. 输入图像 (B, 3, 256, 512)
   ↓
2. Glance网络提取全局特征 (B, 196, 384)
   ↓
3. 初始化序列状态 h_t (B, 1, 384)
   ↓
4. 循环30步：
   a. 根据当前位置crop局部patch (B, 3, 224, 224)
   b. Focus网络提取局部特征 (B, 196, 384)
   c. 更新全局特征（Cross-Attention）
   d. 融合全局和局部特征（门控融合）
   e. 编码位置（周期性编码）
   f. 空间注意力
   g. Mamba序列建模
   h. VAE概率预测
   i. 解码位置 (B, 2)
   j. Y方向注意力偏置
   k. Wrap around处理
   l. 保存位置
   ↓
5. 输出完整扫描路径 (B, 30, 2)
```

---

## 六、评估指标

### 6.1 主要指标

**位置**：`metrics/scanpath_metrics.py`

1. **LEV (Levenshtein Distance)**：
   - 编辑距离，使用软匹配（距离阈值0.20）
   - 越小越好

2. **DTW (Dynamic Time Warping)**：
   - 动态时间规整距离
   - 越小越好

3. **REC (Recurrence)**：
   - 重现率，访问的相同网格数量
   - 越大越好

### 6.2 扩展指标

4. **SIM (Similarity)**：
   - 平均欧氏距离
   - 越小越好

5. **MultiMatch指标**：
   - **MM_Vector**：方向相似度（余弦相似度）
   - **MM_Length**：步长相似度（相关系数）
   - **MM_Position**：位置相似度

6. **显著性指标**（如果提供显著性图）：
   - **NSS**：归一化扫描路径显著性
   - **CC**：相关系数
   - **SalCoverage**：显著性覆盖

---

## 七、模型参数统计

### 7.1 参数量估算

- **Glance网络**：~2M参数
- **Focus网络**：~1.5M参数
- **Mamba模块**：~1M参数
- **特征更新**：~0.5M参数
- **VAE编码/解码器**：~0.5M参数
- **其他模块**：~0.5M参数

**总计**：约6M参数

### 7.2 计算复杂度

- **Glance网络**：O(H×W×C) = O(256×512×384) ≈ 50M FLOPs
- **Focus网络**（每步）：O(224×224×384) ≈ 20M FLOPs × 30步 = 600M FLOPs
- **Mamba**（每步）：O(n×d²) ≈ O(10×384²) ≈ 1.5M FLOPs × 30步 = 45M FLOPs
- **特征更新**（每步）：O(196×384) ≈ 75K FLOPs × 30步 = 2.25M FLOPs

**总计**：约700M FLOPs（单次前向传播）

---

## 八、关键创新总结

### 8.1 架构创新

1. **Mamba + AdaptiveNN融合**：
   - Mamba提供长期依赖建模能力
   - AdaptiveNN的Focus机制提供高分辨率局部特征
   - 两者互补，实现全局-局部协同

2. **双流特征提取**：
   - Glance：快速全局理解
   - Focus：精细局部分析
   - 动态更新：根据注视点位置更新全局表示

3. **360度图像特殊处理**：
   - 球面卷积：考虑球面几何特性
   - Wrap around：处理左右边界连续性
   - 周期性位置编码：捕获经度的周期性

### 8.2 训练创新

1. **多损失函数组合**：
   - 7种损失函数，覆盖位置、方向、平滑、覆盖等多个维度
   - 动态权重调整，适应不同训练阶段

2. **改进的Teacher Forcing**：
   - 指数衰减策略
   - 前几步额外加权
   - 平滑过渡到自由生成

3. **自动停止机制**：
   - 学习何时停止生成
   - 适应变长序列

### 8.3 技术细节

1. **VAE概率建模**：
   - 防止过拟合
   - 增加预测多样性
   - 温度采样控制

2. **Y方向注意力**：
   - 鼓励Y方向多样性
   - 避免预测聚集在中心

3. **位置编码**：
   - 周期性编码（X坐标）
   - 非周期性编码（Y坐标）
   - 融合历史位置信息

---

## 九、潜在改进方向

### 9.1 架构改进

1. **多尺度特征融合**：
   - 引入FPN（Feature Pyramid Network）
   - 融合不同尺度的特征

2. **注意力机制增强**：
   - 引入Spatial Transformer
   - 自适应关注重要区域

3. **序列建模改进**：
   - 尝试其他SSM变体（如S4、Hippo）
   - 混合架构（Mamba + Transformer）

### 9.2 训练改进

1. **课程学习**：
   - 从简单样本到复杂样本
   - 从短序列到长序列

2. **对抗训练**：
   - 引入判别器
   - 提高生成质量

3. **强化学习**：
   - 使用PPO等算法
   - 直接优化评估指标

### 9.3 应用扩展

1. **多模态融合**：
   - 结合音频、文本等多模态信息
   - 提高预测准确性

2. **实时应用**：
   - 模型压缩
   - 推理加速

3. **个性化**：
   - 用户特定模型
   - 适应不同用户习惯

---

## 十、总结

本模型通过结合Mamba状态空间模型和AdaptiveNN的Focus机制，实现了高效的360度全景图像扫描路径生成。模型的核心优势包括：

1. **高效的序列建模**：Mamba提供O(n)复杂度的长期依赖建模
2. **精细的特征提取**：双流架构（Glance+Focus）实现全局-局部协同
3. **360度图像适配**：球面卷积和wrap around处理专门优化
4. **概率建模**：VAE增加多样性，防止过拟合
5. **完善的训练策略**：多损失函数组合和动态Teacher Forcing

该模型在扫描路径生成任务上具有良好的性能，同时保持了较高的计算效率。

---

**报告生成时间**：2024年
**模型版本**：Mamba-Adaptive Scanpath Generator v1.0
**代码位置**：`scanpath_mamba_agent/scanpath_mamba_agent/`
