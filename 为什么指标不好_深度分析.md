# 为什么我们的模型指标不好？深度分析

## 指标计算方式理解

根据 `pingguzhibiao.txt` 的说明，我们现在完全理解了三个指标的计算方式：

### LEV（Levenshtein距离）
- **计算方式**: 将预测序列转换为真实序列所需的最小编辑操作数
- **匹配判定**: 两个注视点的**球面距离** ≤ 阈值时判定为"匹配"
- **关键**: 需要序列在**时间顺序**和**空间位置**上都对齐

### DTW（动态时间规整）
- **计算方式**: 通过弹性对齐找到两序列的最小累积球面距离
- **关键**: 允许时间轴的拉伸/压缩，但仍需要空间位置接近

### REC（复发度量）
- **计算方式**: 量化GT路径与预测路径中"复发事件"的重合程度
- **关键**: 衡量注视点的重复模式是否相似

---

## 🔴 我们的模型为什么指标不好？

### 核心问题：我们的模型根本没有学会"复制"真实路径！

让我重新审视我们的训练结果：

```
LEV = 29.90（序列长度30）
→ 需要29.90次编辑操作才能匹配
→ 99.7%的序列不匹配
→ 说明：预测路径与真实路径在时间顺序和空间位置上几乎完全不同
```

---

## 💡 根本原因分析

### 原因1: 我们的训练目标与评估指标不一致 🔴🔴🔴

**评估指标要求**:
- LEV/DTW/REC都要求预测路径与**某一条特定的真实路径**高度相似
- 需要在**时间顺序**和**空间位置**上都对齐
- 本质上是要求模型"复制"真实路径

**我们的训练目标**:
```python
# 1. 重构损失：整体MSE
reconstruction_loss = F.mse_loss(predicted_scanpaths, true_scanpaths)
# → 只要求整体位置接近，不要求时间顺序对齐

# 2. 序列对齐损失：只约束前5步
sequence_alignment_loss = compute_sequence_alignment_loss(pred[:, :5], true[:, :5])
# → 只约束前5步，后25步完全自由

# 3. 多样性损失：鼓励不同样本生成不同路径
batch_diversity_loss = compute_batch_diversity_loss(predicted_scanpaths)
# → 与"复制真实路径"的目标相反！
```

**矛盾**:
- 评估指标要求：**精确复制**真实路径（时间+空间对齐）
- 我们的训练：**只约束前5步**，后25步自由，还鼓励多样性
- **结果**: LEV/DTW/REC指标必然很差！

---

### 原因2: VAE的随机性与评估指标冲突 🔴🔴

**VAE的设计目的**:
```python
# VAE通过随机采样增加多样性
z = self.reparameterize(mu, logvar, temperature)
# → 每次生成都不同
# → 增加预测的多样性
```

**评估指标的要求**:
- LEV/DTW/REC要求预测路径与真实路径**高度一致**
- 随机性会导致预测路径每次都不同
- **与评估指标的"一致性"要求冲突**

**我们还提高了KL散度权重**:
```python
'kl': 0.005 → 0.01 → 0.02  # 提高随机性
```
- 这进一步增加了随机性
- 进一步恶化了LEV/DTW/REC指标

---

### 原因3: 使用真实起始点但后续自由生成 🔴

**当前策略**:
```python
# 使用真实起始点
if use_gt_start and gt_positions is not None:
    prev_pos = gt_positions[:, 0, :].clone()

# 但后续步骤自由生成（只有前5步有约束）
```

**问题**:
- 起始点对齐了，但后续路径完全不同
- LEV仍然很高（29.90），因为只有第1步匹配
- 就像：起点相同，但走的路线完全不同

---

### 原因4: 球面距离计算可能有问题 🟡

**评估指标要求**:
```
球面距离 = arccos(sin(θ₁)sin(θ₂) + cos(θ₁)cos(θ₂)cos(Δφ))
```

**我们的模型**:
```python
# 我们使用的是2D欧氏距离
reconstruction_loss = F.mse_loss(predicted_scanpaths, true_scanpaths)
# → 没有考虑360度球面特性
```

**问题**:
- 训练时用2D欧氏距离
- 评估时用球面距离
- **距离度量不一致**

---

## 🎯 为什么其他模型能做好？

让我们思考一下，论文中的其他模型（ScanGAN等）是如何做的：

### 1. 他们可能使用了更强的序列约束

**可能的策略**:
- 约束**所有30步**，而不是只约束前5步
- 使用更高的重构损失权重
- 不使用VAE的随机性（或KL权重很低）

### 2. 他们可能使用了球面距离作为损失

**可能的策略**:
```python
# 使用球面距离而非欧氏距离
def spherical_distance(pred, true):
    # 计算球面距离
    return arccos(...)

loss = spherical_distance(pred, true)
```

### 3. 他们可能没有追求多样性

**可能的策略**:
- 不使用Batch多样性损失
- 不鼓励样本间差异
- 目标就是"精确复制"真实路径

---

## 🔧 如何改进？

### 方案A: 完全改变训练目标（激进）⭐⭐⭐

**目标**: 让模型学会"精确复制"真实路径

**修改**:
1. **约束所有30步**（而非只约束前5步）
```python
def compute_full_sequence_alignment_loss(pred, true):
    # 约束所有30步
    distances = torch.norm(pred - true, dim=-1)  # (B, 30)
    weights = torch.ones(30)  # 所有步骤权重相同
    return torch.mean(distances * weights)
```

2. **移除Batch多样性损失**
```python
# 删除这个损失
# batch_diversity_loss = compute_batch_diversity_loss(...)
```

3. **大幅降低KL散度权重**
```python
'kl': 0.001  # 降低到最低（减少随机性）
```

4. **提高重构损失权重**
```python
'reconstruction': 2.0  # 提高到2.0
```

5. **使用球面距离**
```python
def spherical_distance_loss(pred, true):
    """
    计算球面距离损失
    pred, true: (B, T, 2) - 归一化坐标[0,1]
    """
    # 转换为球面坐标
    # x ∈ [0,1] → φ ∈ [0, 2π]（经度）
    # y ∈ [0,1] → θ ∈ [0, π]（纬度）
    phi_pred = pred[:, :, 0] * 2 * math.pi
    theta_pred = pred[:, :, 1] * math.pi
    phi_true = true[:, :, 0] * 2 * math.pi
    theta_true = true[:, :, 1] * math.pi

    # 球面距离公式
    cos_dist = (torch.sin(theta_pred) * torch.sin(theta_true) +
                torch.cos(theta_pred) * torch.cos(theta_true) *
                torch.cos(phi_pred - phi_true))
    cos_dist = torch.clamp(cos_dist, -1.0, 1.0)

    spherical_dist = torch.acos(cos_dist)

    return torch.mean(spherical_dist)
```

**预期效果**:
- LEV: 29.90 → **5-10**（大幅改善）
- DTW: 2697 → **1000-1500**（大幅改善）
- REC: 3.7 → **10-15**（大幅改善）
- **但多样性会下降**（这是代价）

---

### 方案B: 平衡精度和多样性（保守）⭐⭐

**目标**: 在保持一定多样性的同时改善指标

**修改**:
1. **约束前15步**（而非5步）
```python
early_steps = 15  # 从5增加到15
```

2. **保留Batch多样性但降低权重**
```python
'batch_diversity': 0.1  # 从0.3-0.5降到0.1
```

3. **适度降低KL权重**
```python
'kl': 0.005  # 从0.01-0.02降到0.005
```

4. **使用球面距离**（同方案A）

**预期效果**:
- LEV: 29.90 → **15-20**（中等改善）
- 多样性: 保持一定水平
- **折中方案**

---

### 方案C: 改变评估方式（另辟蹊径）⭐

**思路**: 如果我们的模型目标是"生成合理的扫描路径"而非"复制真实路径"，那么LEV/DTW/REC可能不是合适的评估指标

**建议使用的指标**:
1. **覆盖率**: 预测路径是否覆盖了显著区域
2. **多样性**: 不同样本是否生成不同路径
3. **合理性**: 路径是否平滑、连贯
4. **显著性对齐**: 注视点是否落在显著区域

**问题**: 这需要重新定义评估标准，可能不符合论文要求

---

## 📊 三种方案对比

| 方案 | LEV改善 | 多样性 | 实施难度 | 推荐度 |
|------|---------|--------|---------|--------|
| **方案A（激进）** | ⭐⭐⭐⭐⭐ | ❌ 下降 | 中等 | ⭐⭐⭐ |
| **方案B（保守）** | ⭐⭐⭐ | ⚠️ 保持 | 简单 | ⭐⭐ |
| **方案C（另辟蹊径）** | - | ✅ 保持 | 困难 | ⭐ |

---

## 🎓 核心洞察

### 1. 评估指标与训练目标的根本矛盾

**LEV/DTW/REC的本质**:
- 要求模型"精确复制"某一条真实路径
- 强调时间顺序和空间位置的双重对齐
- 不鼓励多样性

**我们的训练目标**:
- 生成"合理的"扫描路径
- 鼓励多样性（VAE + Batch多样性）
- 只约束前5步

**结论**: **这是两个完全不同的目标！**

### 2. VAE不适合这个任务

如果评估指标要求"精确复制"，那么：
- VAE的随机性是**负面因素**
- 应该使用**确定性模型**
- 或者将KL权重降到接近0

### 3. 多样性与评估指标不兼容

- 追求多样性 → LEV/DTW/REC必然差
- 追求LEV/DTW/REC → 多样性必然差
- **必须做出选择**

---

## 🚀 我的建议

### 推荐：方案A（激进改进）

**理由**:
1. 如果论文要求用LEV/DTW/REC评估，我们必须针对性优化
2. 多样性虽然重要，但不是这些指标的评估目标
3. 我们已经尝试了平衡方案，但效果不好

**具体步骤**:
1. ✅ 约束所有30步（而非5步）
2. ✅ 移除Batch多样性损失
3. ✅ 降低KL权重到0.001
4. ✅ 提高重构损失权重到2.0
5. ✅ 使用球面距离损失
6. ✅ 保持使用真实起始点

**预期**:
- LEV: 29.90 → **5-10**（改善70-83%）
- DTW: 2697 → **1000-1500**（改善44-63%）
- REC: 3.7 → **10-15**（改善170-305%）

---

## 📝 总结

### 为什么我们的模型指标不好？

1. 🔴 **训练目标与评估指标不一致**
   - 评估要求：精确复制真实路径
   - 我们训练：只约束前5步，鼓励多样性

2. 🔴 **VAE的随机性与评估指标冲突**
   - VAE增加多样性
   - 评估要求一致性

3. 🔴 **只约束前5步不够**
   - LEV需要所有30步都对齐
   - 我们只约束了前5步

4. 🟡 **使用2D欧氏距离而非球面距离**
   - 训练和评估的距离度量不一致

### 下一步怎么办？

**如果目标是改善LEV/DTW/REC指标**:
→ 采用方案A（激进改进）
→ 放弃多样性，专注于"精确复制"

**如果目标是生成合理的扫描路径**:
→ 采用方案C（改变评估方式）
→ 使用更合适的评估指标

**你想让我实施哪个方案？**
