"""
Mamba-Adaptiveæ‰«æè·¯å¾„æ¨¡å‹è®­ç»ƒè„šæœ¬
ç»“åˆ Mamba + AdaptiveNN Focusæœºåˆ¶
"""
import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import json
from datetime import datetime
from tqdm import tqdm
from pathlib import Path

from config_mamba_adaptive import MambaAdaptiveConfig
from data.dataset import create_dataloaders
from models.mamba_adaptive_scanpath import MambaAdaptiveScanpath
import math


def compute_teacher_forcing_ratio(epoch, step_idx=None):
    """
    æ”¹è¿›çš„Teacher Forcingç­–ç•¥ï¼ˆå¹³è¡¡ç‰ˆæœ¬ï¼‰
    å¿«é€ŸéªŒè¯ç‰ˆæœ¬ï¼šé€‚åº”50ä¸ªepoch

    Args:
        epoch: å½“å‰è®­ç»ƒè½®æ¬¡
        step_idx: å½“å‰åºåˆ—ä¸­çš„æ­¥éª¤ç´¢å¼•ï¼ˆ0-29ï¼‰ï¼Œç”¨äºå‰å‡ æ­¥ä¿æŒé«˜TF
    """
    initial_ratio = 0.8  # é™ä½åˆå§‹æ¯”ä¾‹ï¼ˆä»0.9åˆ°0.8ï¼‰
    final_ratio = 0.2  # é™ä½æœ€ç»ˆæ¯”ä¾‹ï¼ˆä»0.5åˆ°0.2ï¼‰ï¼Œè®©æ¨¡å‹å­¦ä¼šè‡ªä¸»ç”Ÿæˆ
    decay_epochs = 50  # è°ƒæ•´ä¸º50 epoch

    # æŒ‡æ•°è¡°å‡: ratio = 0.8 * exp(-k * epoch)
    k = -math.log(final_ratio / initial_ratio) / decay_epochs
    base_ratio = initial_ratio * math.exp(-k * epoch)
    base_ratio = max(base_ratio, final_ratio)

    # å‰å‡ æ­¥å¹³æ»‘è¡°å‡ï¼ˆè€Œä¸æ˜¯çªå˜ï¼‰
    if step_idx is not None:
        if step_idx < 3:
            # å‰3æ­¥ï¼šé¢å¤–+0.15
            return min(base_ratio + 0.15, 0.95)
        elif step_idx < 6:
            # 3-6æ­¥ï¼šé¢å¤–+0.08
            return min(base_ratio + 0.08, 0.90)
        elif step_idx < 10:
            # 6-10æ­¥ï¼šé¢å¤–+0.03
            return min(base_ratio + 0.03, 0.85)

    return base_ratio


def compute_spatial_coverage_loss(pred_scanpaths):
    """åˆå¹¶è¦†ç›–èŒƒå›´ã€å¤šæ ·æ€§å’Œä¸­å¿ƒèšé›†æƒ©ç½šï¼ˆæ”¹è¿›ç‰ˆï¼šæé«˜Yæ–¹å‘è¦†ç›–ï¼‰"""
    # è¦†ç›–èŒƒå›´
    pred_min = pred_scanpaths.min(dim=1)[0]
    pred_max = pred_scanpaths.max(dim=1)[0]
    pred_range = pred_max - pred_min

    # æé«˜è¦†ç›–ç›®æ ‡ï¼šXæ–¹å‘0.5ï¼ŒYæ–¹å‘0.5ï¼ˆä¹‹å‰æ˜¯0.3å’Œ0.25ï¼‰
    coverage_x = torch.mean(((0.5 - pred_range[:, 0]).clamp(min=0.0)) ** 2)
    coverage_y = torch.mean(((0.5 - pred_range[:, 1]).clamp(min=0.0)) ** 2)

    # å¤šæ ·æ€§
    pred_mean = pred_scanpaths.mean(dim=1)
    pred_var = ((pred_scanpaths - pred_mean.unsqueeze(1)) ** 2).mean(dim=1)

    diversity_x = torch.mean(((0.015 - pred_var[:, 0]).clamp(min=0.0)) ** 2)
    diversity_y = torch.mean(((0.025 - pred_var[:, 1]).clamp(min=0.0)) ** 2)

    # Yæ–¹å‘ä¸­å¿ƒèšé›†æƒ©ç½šï¼ˆä¿®å¤ï¼šæƒ©ç½šåç¦»0.5çš„ä»»ä½•æ–¹å‘ï¼‰
    y_center_dist = torch.abs(pred_mean[:, 1] - 0.5)
    # å…è®¸Â±0.1çš„åå·®ï¼ˆæ”¾å®½é™åˆ¶ï¼‰ï¼Œè¶…å‡ºåˆ™æƒ©ç½š
    y_bias_penalty = torch.mean((y_center_dist - 0.1).clamp(min=0.0) ** 2)

    # å†…éƒ¨åŠ æƒç»„åˆï¼ˆé™ä½y_bias_penaltyæƒé‡ï¼Œç»™Yæ–¹å‘æ›´å¤šè‡ªç”±ï¼‰
    return coverage_x + 3.0 * coverage_y + diversity_x + 5.0 * diversity_y + 5.0 * y_bias_penalty


def compute_trajectory_smoothness_loss(pred_scanpaths, true_scanpaths):
    """åˆå¹¶æ­¥é•¿ã€è·³è·ƒå’ŒåŠ é€Ÿåº¦çº¦æŸï¼ˆä¿®å¤ï¼šç§»é™¤è¿‡åº¦çš„è·³è·ƒæƒ©ç½šï¼‰"""
    pred_diffs = pred_scanpaths[:, 1:] - pred_scanpaths[:, :-1]
    true_diffs = true_scanpaths[:, 1:] - true_scanpaths[:, :-1]

    pred_steps = torch.norm(pred_diffs, p=2, dim=-1)
    true_steps = torch.norm(true_diffs, p=2, dim=-1)

    # æ­¥é•¿åŒ¹é…
    step_loss = F.mse_loss(pred_steps, true_steps)

    # è·³è·ƒæƒ©ç½šï¼ˆä¿®å¤ï¼šæé«˜é˜ˆå€¼åˆ°0.5ï¼Œå…è®¸æ›´å¤§çš„æ­¥é•¿ï¼‰
    # ä¹‹å‰0.2å¤ªå°ï¼Œå¯¼è‡´è·¯å¾„ç§»åŠ¨è·ç¦»è¿‡çŸ­
    jump_loss = torch.mean((pred_steps - 0.5).clamp(min=0.0) ** 2)

    # åŠ é€Ÿåº¦çº¦æŸ
    if pred_steps.shape[1] > 1:
        pred_accel = pred_steps[:, 1:] - pred_steps[:, :-1]
        true_accel = true_steps[:, 1:] - true_steps[:, :-1]
        accel_loss = F.mse_loss(pred_accel, true_accel)
    else:
        accel_loss = torch.tensor(0.0, device=pred_scanpaths.device)

    # é™ä½jump_lossæƒé‡ï¼ˆä»0.5åˆ°0.1ï¼‰
    return step_loss + 0.1 * jump_loss + 0.3 * accel_loss


def compute_direction_consistency_loss(pred_scanpaths, true_scanpaths):
    """åˆå¹¶æ–¹å‘å˜åŒ–å’Œæ–¹å‘è¿ç»­æ€§"""
    pred_diffs = pred_scanpaths[:, 1:] - pred_scanpaths[:, :-1]
    true_diffs = true_scanpaths[:, 1:] - true_scanpaths[:, :-1]

    pred_steps = torch.norm(pred_diffs, p=2, dim=-1, keepdim=True)
    true_steps = torch.norm(true_diffs, p=2, dim=-1, keepdim=True)

    pred_directions = pred_diffs / (pred_steps + 1e-8)
    true_directions = true_diffs / (true_steps + 1e-8)

    # æ–¹å‘å˜åŒ–
    if pred_directions.shape[1] > 1:
        pred_dir_diffs = pred_directions[:, 1:] - pred_directions[:, :-1]
        true_dir_diffs = true_directions[:, 1:] - true_directions[:, :-1]
        direction_loss = F.mse_loss(
            torch.norm(pred_dir_diffs, p=2, dim=-1),
            torch.norm(true_dir_diffs, p=2, dim=-1)
        )
    else:
        direction_loss = torch.tensor(0.0, device=pred_scanpaths.device)

    # æ–¹å‘è¿ç»­æ€§
    if pred_directions.shape[1] > 0:
        pred_similarity = F.cosine_similarity(pred_directions[:, :-1], pred_directions[:, 1:], dim=-1)
        true_similarity = F.cosine_similarity(true_directions[:, :-1], true_directions[:, 1:], dim=-1)
        continuity_loss = F.mse_loss(pred_similarity, true_similarity)
    else:
        continuity_loss = torch.tensor(0.0, device=pred_scanpaths.device)

    return direction_loss + continuity_loss


def compute_sequence_alignment_loss(pred_scanpaths, true_scanpaths):
    """
    å®Œæ•´åºåˆ—å¯¹é½æŸå¤±ï¼šçº¦æŸæ‰€æœ‰30æ­¥ï¼ˆæ–¹æ¡ˆA - ç²¾ç¡®å¤åˆ¶ï¼Œä¿®å¤ç‰ˆï¼‰

    å…³é”®æ”¹è¿›ï¼š
    - çº¦æŸæ‰€æœ‰30æ­¥ï¼Œç¡®ä¿å®Œæ•´åºåˆ—å¯¹é½
    - é™ä½å†…éƒ¨æƒé‡ï¼Œé¿å…è¿‡åº¦å…³æ³¨å‰å‡ æ­¥å¯¼è‡´è·¯å¾„"å¡ä½"
    - ç›®æ ‡ï¼šè®©æ¨¡å‹å­¦ä¼š"ç²¾ç¡®å¤åˆ¶"çœŸå®è·¯å¾„çš„å®Œæ•´è½¨è¿¹
    """
    B, T, D = pred_scanpaths.shape

    # è®¡ç®—æ‰€æœ‰æ—¶é—´æ­¥çš„ç‚¹å¯¹ç‚¹è·ç¦»
    point_distances = torch.norm(pred_scanpaths - true_scanpaths, dim=-1)  # (B, T)

    # æƒé‡é…ç½®ï¼šé™ä½æƒé‡ï¼Œé¿å…è¿‡åº¦çº¦æŸï¼ˆä¹‹å‰æƒé‡å¤ªé«˜å¯¼è‡´æ¨¡å‹"å¡ä½"ï¼‰
    weights = torch.ones(T, device=pred_scanpaths.device)
    weights[:5] = 3.0  # å‰5æ­¥ï¼šæƒé‡3.0ï¼ˆä»15.0é™ä½ï¼‰
    weights[5:10] = 2.5  # 5-10æ­¥ï¼šæƒé‡2.5ï¼ˆä»10.0é™ä½ï¼‰
    weights[10:15] = 2.0  # 10-15æ­¥ï¼šæƒé‡2.0ï¼ˆä»8.0é™ä½ï¼‰
    weights[15:20] = 1.5  # 15-20æ­¥ï¼šæƒé‡1.5ï¼ˆä»6.0é™ä½ï¼‰
    weights[20:25] = 1.3  # 20-25æ­¥ï¼šæƒé‡1.3ï¼ˆä»5.0é™ä½ï¼‰
    weights[25:] = 1.2  # 25-30æ­¥ï¼šæƒé‡1.2ï¼ˆä»4.0é™ä½ï¼‰

    # è®¡ç®—æ‰€æœ‰30æ­¥çš„åŠ æƒå¹³å‡
    alignment_loss = torch.mean(point_distances * weights.unsqueeze(0))

    return alignment_loss


def compute_motion_consistency_loss(pred_scanpaths, true_scanpaths):
    """
    è¿åŠ¨ä¸€è‡´æ€§æŸå¤±ï¼ˆæ–¹æ¡ˆC-æ”¹è¿›ç‰ˆï¼‰ï¼šé€‰æ‹©æ€§çº¦æŸæ–¹å‘å’Œæ­¥é•¿

    æ”¹è¿›ï¼šåªçº¦æŸ"åˆç†"çš„è¿åŠ¨ï¼Œé¿å…è¿‡åº¦çº¦æŸå¯¼è‡´Nå½¢è·¯å¾„

    åŒ…å«ä¸¤ä¸ªéƒ¨åˆ†ï¼š
    1. æ–¹å‘ç›¸ä¼¼åº¦æŸå¤±ï¼šä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦çº¦æŸè¿åŠ¨æ–¹å‘
    2. æ­¥é•¿ç›¸ä¼¼åº¦æŸå¤±ï¼šä½¿ç”¨MSEçº¦æŸè¿åŠ¨æ­¥é•¿

    å…³é”®æ”¹è¿›ï¼š
    - åªå¯¹æ­¥é•¿åœ¨åˆç†èŒƒå›´å†…çš„è¿åŠ¨è¿›è¡Œçº¦æŸ
    - å¯¹äºè¿‡å°çš„æ­¥é•¿ï¼ˆ< 0.01ï¼‰ï¼Œä¸çº¦æŸæ–¹å‘ï¼ˆé¿å…å™ªå£°ï¼‰
    - å¯¹äºè¿‡å¤§çš„æ­¥é•¿ï¼ˆ> 0.3ï¼‰ï¼Œé™ä½çº¦æŸæƒé‡ï¼ˆå…è®¸æ¢ç´¢ï¼‰

    Args:
        pred_scanpaths: é¢„æµ‹è·¯å¾„ (B, T, 2)
        true_scanpaths: çœŸå®è·¯å¾„ (B, T, 2)

    Returns:
        motion_loss: è¿åŠ¨ä¸€è‡´æ€§æŸå¤±æ ‡é‡
    """
    # è®¡ç®—è¿åŠ¨å‘é‡ï¼ˆç›¸é‚»ç‚¹ä¹‹é—´çš„ä½ç§»ï¼‰
    pred_motions = pred_scanpaths[:, 1:] - pred_scanpaths[:, :-1]  # (B, T-1, 2)
    true_motions = true_scanpaths[:, 1:] - true_scanpaths[:, :-1]  # (B, T-1, 2)

    # è®¡ç®—æ­¥é•¿
    pred_step_lengths = torch.norm(pred_motions, p=2, dim=-1)  # (B, T-1)
    true_step_lengths = torch.norm(true_motions, p=2, dim=-1)  # (B, T-1)

    # 1. æ–¹å‘ç›¸ä¼¼åº¦æŸå¤±ï¼ˆä½™å¼¦ç›¸ä¼¼åº¦ï¼‰- é€‰æ‹©æ€§çº¦æŸ
    # å½’ä¸€åŒ–è¿åŠ¨å‘é‡å¾—åˆ°æ–¹å‘
    pred_directions = F.normalize(pred_motions, p=2, dim=-1, eps=1e-8)  # (B, T-1, 2)
    true_directions = F.normalize(true_motions, p=2, dim=-1, eps=1e-8)  # (B, T-1, 2)

    # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
    cosine_similarity = (pred_directions * true_directions).sum(dim=-1)  # (B, T-1)

    # é€‰æ‹©æ€§çº¦æŸï¼šåªå¯¹åˆç†æ­¥é•¿çš„è¿åŠ¨çº¦æŸæ–¹å‘
    # æ­¥é•¿å¤ªå°ï¼ˆ< 0.01ï¼‰ï¼šå¯èƒ½æ˜¯å™ªå£°ï¼Œä¸çº¦æŸ
    # æ­¥é•¿å¤ªå¤§ï¼ˆ> 0.3ï¼‰ï¼šå¯èƒ½æ˜¯æ¢ç´¢æ€§è·³è·ƒï¼Œé™ä½çº¦æŸ
    step_mask = (true_step_lengths > 0.01) & (true_step_lengths < 0.3)  # (B, T-1)

    # å¯¹äºå¤§æ­¥é•¿ï¼Œä½¿ç”¨è¾ƒå°çš„æƒé‡
    large_step_mask = true_step_lengths >= 0.3
    large_step_weight = 0.3  # å¤§æ­¥é•¿çš„æ–¹å‘çº¦æŸæƒé‡é™ä½åˆ°30%

    # è®¡ç®—åŠ æƒæ–¹å‘æŸå¤±
    direction_loss_per_step = 1.0 - cosine_similarity  # (B, T-1)
    direction_loss_weighted = torch.where(
        step_mask,
        direction_loss_per_step,  # æ­£å¸¸æ­¥é•¿ï¼šå…¨æƒé‡
        torch.where(
            large_step_mask,
            direction_loss_per_step * large_step_weight,  # å¤§æ­¥é•¿ï¼šé™ä½æƒé‡
            torch.zeros_like(direction_loss_per_step)  # å°æ­¥é•¿ï¼šä¸çº¦æŸ
        )
    )
    direction_loss = direction_loss_weighted.mean()

    # 2. æ­¥é•¿ç›¸ä¼¼åº¦æŸå¤±ï¼ˆMSEï¼‰- ä½¿ç”¨ç›¸å¯¹è¯¯å·®è€Œä¸æ˜¯ç»å¯¹è¯¯å·®
    # æ”¹è¿›ï¼šä½¿ç”¨ç›¸å¯¹è¯¯å·®ï¼Œé¿å…å¯¹å¤§æ­¥é•¿è¿‡åº¦æƒ©ç½š
    # ç›¸å¯¹è¯¯å·® = |pred - true| / (true + eps)
    step_relative_error = torch.abs(pred_step_lengths - true_step_lengths) / (true_step_lengths + 1e-6)

    # åªå¯¹åˆç†æ­¥é•¿çº¦æŸ
    step_loss_per_step = step_relative_error ** 2
    step_loss_weighted = torch.where(
        step_mask,
        step_loss_per_step,
        torch.zeros_like(step_loss_per_step)
    )
    step_length_loss = step_loss_weighted.mean()

    # 3. ç»„åˆæŸå¤±ï¼ˆæ–¹å‘å’Œæ­¥é•¿åŒç­‰é‡è¦ï¼‰
    motion_loss = direction_loss + step_length_loss

    return motion_loss


# å·²ç§»é™¤ compute_batch_diversity_loss å‡½æ•°
# æ–¹æ¡ˆAï¼šä¸“æ³¨äºç²¾ç¡®å¤åˆ¶è·¯å¾„ï¼Œä¸é¼“åŠ±å¤šæ ·æ€§


def train():
    """è®­ç»ƒä¸»å‡½æ•°"""
    config = MambaAdaptiveConfig()

    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(config.log_dir, exist_ok=True)
    os.makedirs(config.checkpoint_dir, exist_ok=True)

    # åŠ è½½æ•°æ®
    print("åŠ è½½æ•°æ®...")
    train_loader, test_loader = create_dataloaders(config)
    print(f"è®­ç»ƒé›†: {len(train_loader)} batches")
    print(f"æµ‹è¯•é›†: {len(test_loader)} batches")

    # åˆ›å»ºæ¨¡å‹
    print("\nåˆ›å»ºMamba-Adaptiveæ¨¡å‹ï¼ˆç»“åˆFocusæœºåˆ¶ï¼‰...")
    model = MambaAdaptiveScanpath(config).to(config.device)
    print(f"æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters()) / 1e6:.2f}M")

    # ä¼˜åŒ–å™¨
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=config.learning_rate,
        weight_decay=config.weight_decay
    )

    # å­¦ä¹ ç‡è°ƒåº¦å™¨ - ä½¿ç”¨ä½™å¼¦é€€ç«ï¼ˆæ›´å¥½çš„æ”¶æ•›æ€§ï¼‰
    # è®­ç»ƒç›®æ ‡ï¼šå­¦ä¹ ç‡åœ¨å‰åŠç¨‹è¾ƒé«˜ï¼ˆå¿«é€Ÿå­¦ä¹ ï¼‰ï¼ŒååŠç¨‹è¾ƒä½ï¼ˆç²¾ç»†è°ƒä¼˜ï¼‰
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer,
        T_max=config.num_epochs,
        eta_min=config.learning_rate * 0.01  # æœ€å°å­¦ä¹ ç‡ä¸ºåˆå§‹çš„1%
    )

    # æ—©åœæœºåˆ¶ï¼šåŸºäºéªŒè¯ä½ç½®è¯¯å·®è€Œä¸æ˜¯æŸå¤±
    # å¿«é€ŸéªŒè¯é…ç½®ï¼šå‡å°‘patience
    best_val_position_error = float('inf')
    patience_counter = 0
    early_stopping_patience = 10  # å‡å°‘åˆ°10ï¼ˆä»20ï¼‰ï¼Œå¿«é€Ÿæ­¢æŸ
    best_val_loss = float('inf')  # ä»ç„¶è®°å½•ï¼Œä½†ç”¨äºä¿å­˜æ¨¡å‹

    # è®­ç»ƒæ—¥å¿—
    training_log = {
        'config': {
            'seq_len': config.seq_len,
            'batch_size': config.batch_size,
            'learning_rate': config.learning_rate,
            'num_epochs': config.num_epochs,
            'feature_dim': config.feature_dim,
            'd_state': config.d_state,
            'focus_patch_size': config.focus_patch_size,
        },
        'epochs': []
    }

    # è®­ç»ƒå¾ªç¯
    print("\nå¼€å§‹è®­ç»ƒ...")
    best_loss = float('inf')

    for epoch in range(1, config.num_epochs + 1):
        print(f"\n{'=' * 80}")
        print(f"Epoch {epoch}/{config.num_epochs}")
        print(f"{'=' * 80}")

        # è®­ç»ƒ
        model.train()
        epoch_loss = 0
        epoch_position_error = 0

        train_bar = tqdm(train_loader, desc="è®­ç»ƒ")
        for batch_idx, batch in enumerate(train_bar):
            images = batch['image'].to(config.device)
            true_scanpaths = batch['scanpath'].to(config.device)

            # å‰å‘ä¼ æ’­ - ä¼ é€’çœŸå®ä½ç½®ç”¨äºTeacher Forcing
            # æ”¹è¿›Teacher Forcingç­–ç•¥ï¼šæŒ‡æ•°è¡°å‡
            teacher_forcing_ratio = compute_teacher_forcing_ratio(epoch)

            # è®­ç»ƒæ—¶æ˜¾å¼è®¾ç½®enable_early_stop=Falseï¼Œç¡®ä¿è¿”å›3ä¸ªå€¼
            # use_gt_start=True ç¡®ä¿ä½¿ç”¨çœŸå®èµ·å§‹ç‚¹ï¼Œæ”¹å–„LEVæŒ‡æ ‡
            predicted_scanpaths, mus, logvars = model(
                images,
                gt_scanpaths=true_scanpaths,
                teacher_forcing_ratio=teacher_forcing_ratio,
                enable_early_stop=False,
                use_gt_start=True  # ä½¿ç”¨çœŸå®èµ·å§‹ç‚¹
            )

            # ========== æ–¹æ¡ˆAï¼šç²¾ç¡®å¤åˆ¶è·¯å¾„çš„æŸå¤±å‡½æ•° ==========
            # 1. é‡æ„æŸå¤±ï¼ˆå‡†ç¡®åŒ¹é…çœŸå®è·¯å¾„ï¼‰- æé«˜æƒé‡
            reconstruction_loss = nn.functional.mse_loss(predicted_scanpaths, true_scanpaths)

            # 2. KLæ•£åº¦æ­£åˆ™åŒ–ï¼ˆé™ä½æƒé‡ï¼Œå‡å°‘éšæœºæ€§ï¼‰
            kl_loss = -0.5 * torch.sum(1 + logvars - mus.pow(2) - logvars.exp())
            kl_loss = kl_loss / (mus.size(0) * mus.size(1))  # å½’ä¸€åŒ–

            # 3. ç©ºé—´è¦†ç›–æŸå¤±ï¼ˆä¿æŒé€‚åº¦çº¦æŸï¼‰
            spatial_coverage_loss = compute_spatial_coverage_loss(predicted_scanpaths)

            # 4. è½¨è¿¹å¹³æ»‘æŸå¤±ï¼ˆä¿æŒè½¨è¿¹å¹³æ»‘ï¼‰
            trajectory_smoothness_loss = compute_trajectory_smoothness_loss(predicted_scanpaths, true_scanpaths)

            # 5. æ–¹å‘ä¸€è‡´æ€§æŸå¤±ï¼ˆä¿æŒæ–¹å‘ä¸€è‡´ï¼‰
            direction_consistency_loss = compute_direction_consistency_loss(predicted_scanpaths, true_scanpaths)

            # 6. åºåˆ—å¯¹é½æŸå¤±ï¼ˆçº¦æŸæ‰€æœ‰30æ­¥ï¼Œå¤§å¹…æé«˜æƒé‡ï¼‰
            sequence_alignment_loss = compute_sequence_alignment_loss(predicted_scanpaths, true_scanpaths)

            # 7. è¿åŠ¨ä¸€è‡´æ€§æŸå¤±ï¼ˆæ–¹æ¡ˆCï¼šæ˜¾å¼çº¦æŸæ–¹å‘å’Œæ­¥é•¿ï¼‰
            motion_consistency_loss = compute_motion_consistency_loss(predicted_scanpaths, true_scanpaths)

            # 8. è¾¹ç•Œçº¦æŸ
            boundary_min = 0.02
            boundary_max = 0.98
            below_boundary = (predicted_scanpaths < boundary_min).float()
            above_boundary = (predicted_scanpaths > boundary_max).float()
            boundary_penalty = torch.mean(
                below_boundary * (boundary_min - predicted_scanpaths) ** 2 +
                above_boundary * (predicted_scanpaths - boundary_max) ** 2
            )

            # ========== ç¬¬äºŒæ¬¡ä¿®å¤ç‰ˆæƒé‡é…ç½®ï¼šè§£å†³æ­¥é•¿è¿‡çŸ­å’Œè¿‡æ‹Ÿåˆé—®é¢˜ ==========
            # æ–°é—®é¢˜è¯Šæ–­ï¼š
            # 1. æ­¥é•¿è¿‡çŸ­ï¼šSalCoverageä»56%é™åˆ°15%ï¼Œè·¯å¾„ç§»åŠ¨è·ç¦»å¤ªçŸ­
            # 2. è¿‡æ‹Ÿåˆä¸¥é‡ï¼šè®­ç»ƒ0.113 vs éªŒè¯0.357ï¼ˆ3å€å·®è·ï¼‰
            # 3. KL=0.0001å¤ªä½ï¼šæ¨¡å‹é€€åŒ–ä¸ºç¡®å®šæ€§ï¼Œæ— æ³•æ³›åŒ–
            #
            # è§£å†³æ–¹æ¡ˆï¼š
            # 1. æé«˜KLæ•£åº¦æƒé‡ï¼ˆ0.0001 â†’ 0.001ï¼‰ï¼Œæ¢å¤é€‚åº¦éšæœºæ€§
            # 2. é™ä½trajectory_smoothnessæƒé‡ï¼ˆ0.3 â†’ 0.1ï¼‰ï¼Œå…è®¸æ›´å¤§æ­¥é•¿
            # 3. æé«˜spatial_coverageæƒé‡ï¼ˆ1.0 â†’ 2.0ï¼‰ï¼Œé¼“åŠ±æ¢ç´¢
            # 4. é™ä½reconstructionæƒé‡ï¼ˆ5.0 â†’ 3.0ï¼‰ï¼Œå‡å°‘è¿‡æ‹Ÿåˆ
            if epoch <= 20:
                weights = {
                    'reconstruction': 3.0,  # é™ä½ï¼ˆä»5.0åˆ°3.0ï¼‰ï¼Œå‡å°‘è¿‡æ‹Ÿåˆ
                    'kl': 0.001,  # æé«˜ï¼ˆä»0.0001åˆ°0.001ï¼‰ï¼Œæ¢å¤éšæœºæ€§
                    'spatial_coverage': 2.0,  # æé«˜ï¼ˆä»1.0åˆ°2.0ï¼‰ï¼Œé¼“åŠ±æ¢ç´¢
                    'trajectory_smoothness': 0.1,  # é™ä½ï¼ˆä»0.3åˆ°0.1ï¼‰ï¼Œå…è®¸å¤§æ­¥é•¿
                    'direction_consistency': 0.2,  # é™ä½ï¼ˆä»0.3åˆ°0.2ï¼‰
                    'sequence_alignment': 2.0,  # é™ä½ï¼ˆä»3.0åˆ°2.0ï¼‰
                    'motion_consistency': 0.05,
                    'boundary': 0.2
                }
            elif epoch <= 40:
                progress = (epoch - 20) / 20.0
                weights = {
                    'reconstruction': 3.0 + 0.5 * progress,  # é€æ¸å¢åŠ åˆ°3.5
                    'kl': 0.001 + 0.0005 * progress,  # é€æ¸å¢åŠ åˆ°0.0015
                    'spatial_coverage': 2.0 + 0.5 * progress,  # é€æ¸å¢åŠ åˆ°2.5
                    'trajectory_smoothness': 0.1,
                    'direction_consistency': 0.2,
                    'sequence_alignment': 2.0 + 0.5 * progress,  # é€æ¸å¢åŠ åˆ°2.5
                    'motion_consistency': 0.05 + 0.05 * progress,  # é€æ¸å¢åŠ åˆ°0.1
                    'boundary': 0.2
                }
            else:
                weights = {
                    'reconstruction': 3.5,  # æœ€ç»ˆæƒé‡ï¼ˆé€‚ä¸­ï¼‰
                    'kl': 0.0015,  # æœ€ç»ˆæƒé‡ï¼ˆé€‚ä¸­ï¼‰
                    'spatial_coverage': 2.5,  # æœ€ç»ˆæƒé‡ï¼ˆé«˜ï¼‰
                    'trajectory_smoothness': 0.1,  # ä¿æŒä½
                    'direction_consistency': 0.2,
                    'sequence_alignment': 2.5,
                    'motion_consistency': 0.1,
                    'boundary': 0.2
                }

            # è®¡ç®—æ€»æŸå¤±ï¼ˆæ·»åŠ motion_consistencyé¡¹ï¼‰
            loss = (
                    weights['reconstruction'] * reconstruction_loss +
                    weights['kl'] * kl_loss +
                    weights['spatial_coverage'] * spatial_coverage_loss +
                    weights['trajectory_smoothness'] * trajectory_smoothness_loss +
                    weights['direction_consistency'] * direction_consistency_loss +
                    weights['sequence_alignment'] * sequence_alignment_loss +
                    weights['motion_consistency'] * motion_consistency_loss +
                    weights['boundary'] * boundary_penalty
            )

            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()

            # è®¡ç®—ä½ç½®è¯¯å·®
            position_weights_error = torch.ones(config.seq_len, device=predicted_scanpaths.device)
            if epoch <= 80:
                position_weights_error[0] = 2.5
                position_weights_error[1:5] = 1.8
                position_weights_error[5:10] = 1.3
            else:
                position_weights_error[0] = 2.0
                position_weights_error[1:5] = 1.5
                position_weights_error[5:10] = 1.2

            # åŠ æƒä½ç½®è¯¯å·®
            weighted_errors = torch.norm(
                predicted_scanpaths - true_scanpaths,
                dim=-1
            ) * position_weights_error.unsqueeze(0)
            position_error = weighted_errors.mean() / position_weights_error.mean()  # å½’ä¸€åŒ–ä»¥ä¿æŒåŸæœ‰å°ºåº¦

            # ç´¯ç§¯æŒ‡æ ‡
            epoch_loss += loss.item()
            epoch_position_error += position_error.item()

            # æ›´æ–°è¿›åº¦æ¡
            if (batch_idx + 1) % config.log_interval == 0:
                avg_loss = epoch_loss / (batch_idx + 1)
                avg_error = epoch_position_error / (batch_idx + 1)
                train_bar.set_postfix({
                    'Loss': f"{avg_loss:.4f}",
                    'PosErr': f"{avg_error:.4f}",
                    'TF': f"{teacher_forcing_ratio:.3f}",
                    'SeqAlign': f"{sequence_alignment_loss.item():.4f}",
                    'Recon': f"{reconstruction_loss.item():.4f}",
                    'KL': f"{kl_loss.item():.5f}",
                })

        # å¹³å‡è®­ç»ƒæŒ‡æ ‡
        num_batches = len(train_loader)
        epoch_loss /= num_batches
        epoch_position_error /= num_batches

        # æ‰“å°è®­ç»ƒç»“æœ
        print(f"\nè®­ç»ƒç»“æœ:")
        print(f"  Loss: {epoch_loss:.4f}")
        print(f"  PositionError: {epoch_position_error:.4f}")

        # éªŒè¯
        if epoch % config.val_interval == 0:
            print(f"\néªŒè¯...")
            model.eval()
            val_loss = 0
            val_position_error = 0

            val_bar = tqdm(test_loader, desc="éªŒè¯")
            with torch.no_grad():
                for batch in val_bar:
                    images = batch['image'].to(config.device)
                    true_scanpaths = batch['scanpath'].to(config.device)

                    # å‰å‘ä¼ æ’­ - éªŒè¯æ¨¡å¼
                    # å¹³è¡¡ç‰ˆæœ¬ï¼šéªŒè¯æ—¶ä½¿ç”¨æ›´ä½çš„Teacher Forcing
                    val_teacher_forcing = max(0.1, teacher_forcing_ratio * 0.3)
                    result = model(images, gt_scanpaths=true_scanpaths,
                                   teacher_forcing_ratio=val_teacher_forcing,
                                   enable_early_stop=False,
                                   use_gt_start=True)  # éªŒè¯æ—¶ä¹Ÿä½¿ç”¨çœŸå®èµ·å§‹ç‚¹
                    # å®‰å…¨è§£åŒ…ï¼šæ— è®ºè¿”å›3ä¸ªè¿˜æ˜¯5ä¸ªå€¼ï¼Œéƒ½åªå–å‰3ä¸ª
                    predicted_scanpaths = result[0]
                    mus = result[1]
                    logvars = result[2]

                    # ========== æ–¹æ¡ˆAéªŒè¯æŸå¤±ï¼ˆä¸è®­ç»ƒä¸€è‡´ï¼‰==========
                    # 1. é‡æ„æŸå¤±
                    reconstruction_loss = nn.functional.mse_loss(predicted_scanpaths, true_scanpaths)

                    # 2. KLæ•£åº¦æ­£åˆ™åŒ–
                    kl_loss = -0.5 * torch.sum(1 + logvars - mus.pow(2) - logvars.exp())
                    kl_loss = kl_loss / (mus.size(0) * mus.size(1))

                    # 3. ç©ºé—´è¦†ç›–æŸå¤±
                    spatial_coverage_loss = compute_spatial_coverage_loss(predicted_scanpaths)

                    # 4. è½¨è¿¹å¹³æ»‘æŸå¤±
                    trajectory_smoothness_loss = compute_trajectory_smoothness_loss(predicted_scanpaths, true_scanpaths)

                    # 5. æ–¹å‘ä¸€è‡´æ€§æŸå¤±
                    direction_consistency_loss = compute_direction_consistency_loss(predicted_scanpaths, true_scanpaths)

                    # 6. åºåˆ—å¯¹é½æŸå¤±
                    sequence_alignment_loss = compute_sequence_alignment_loss(predicted_scanpaths, true_scanpaths)

                    # 7. è¾¹ç•Œçº¦æŸ
                    boundary_min = 0.02
                    boundary_max = 0.98
                    below_boundary = (predicted_scanpaths < boundary_min).float()
                    above_boundary = (predicted_scanpaths > boundary_max).float()
                    boundary_penalty = torch.mean(
                        below_boundary * (boundary_min - predicted_scanpaths) ** 2 +
                        above_boundary * (predicted_scanpaths - boundary_max) ** 2
                    )

                    # ä½¿ç”¨ä¸è®­ç»ƒç›¸åŒçš„æƒé‡ï¼ˆæ–¹æ¡ˆA - æ”¹è¿›ç‰ˆï¼‰
                    if epoch <= 20:
                        weights = {
                            'reconstruction': 2.0,
                            'kl': 0.003,
                            'spatial_coverage': 2.0,
                            'trajectory_smoothness': 0.3,
                            'direction_consistency': 0.3,
                            'sequence_alignment': 1.5,
                            'boundary': 0.2
                        }
                    elif epoch <= 40:
                        progress = (epoch - 20) / 20.0
                        weights = {
                            'reconstruction': 2.0 + 0.5 * progress,
                            'kl': 0.003,
                            'spatial_coverage': 2.0 + 0.5 * progress,
                            'trajectory_smoothness': 0.3,
                            'direction_consistency': 0.3,
                            'sequence_alignment': 1.5 + 0.5 * progress,
                            'boundary': 0.2
                        }
                    else:
                        weights = {
                            'reconstruction': 2.5,
                            'kl': 0.003,
                            'spatial_coverage': 2.5,
                            'trajectory_smoothness': 0.3,
                            'direction_consistency': 0.3,
                            'sequence_alignment': 2.0,
                            'boundary': 0.2
                        }

                    # è®¡ç®—æ€»æŸå¤±ï¼ˆç§»é™¤batch_diversityé¡¹ï¼‰
                    loss = (
                            weights['reconstruction'] * reconstruction_loss +
                            weights['kl'] * kl_loss +
                            weights['spatial_coverage'] * spatial_coverage_loss +
                            weights['trajectory_smoothness'] * trajectory_smoothness_loss +
                            weights['direction_consistency'] * direction_consistency_loss +
                            weights['sequence_alignment'] * sequence_alignment_loss +
                            weights['boundary'] * boundary_penalty
                    )

                    # è®¡ç®—ä½ç½®è¯¯å·®
                    position_error = torch.norm(
                        predicted_scanpaths - true_scanpaths,
                        dim=-1
                    ).mean()

                    val_loss += loss.item()
                    val_position_error += position_error.item()

            # å¹³å‡éªŒè¯æŒ‡æ ‡
            num_val_batches = len(test_loader)
            val_loss /= num_val_batches
            val_position_error /= num_val_batches

            print(f"\néªŒè¯ç»“æœ:")
            print(f"  Loss: {val_loss:.4f}")
            print(f"  PositionError: {val_position_error:.4f}")

            # å­¦ä¹ ç‡è°ƒåº¦ - ExponentialLRåœ¨æ¯ä¸ªepochåè‡ªåŠ¨è¡°å‡
            current_lr = optimizer.param_groups[0]['lr']
            print(f"  Learning Rate: {current_lr:.6f}")

            # ä¿å­˜æœ€ä½³æ¨¡å‹ï¼šä¼˜å…ˆåŸºäºä½ç½®è¯¯å·®ï¼Œä¹Ÿè€ƒè™‘æŸå¤±
            save_model = False
            if val_position_error < best_val_position_error:
                best_val_position_error = val_position_error
                save_model = True
                patience_counter = 0  # é‡ç½®æ—©åœè®¡æ•°å™¨ï¼ˆåŸºäºä½ç½®è¯¯å·®ï¼‰
                print(f"  âœ… éªŒè¯ä½ç½®è¯¯å·®æ”¹å–„: {val_position_error:.4f} (æ–°æœ€ä½³)")

            if val_loss < best_val_loss:
                best_val_loss = val_loss
                if not save_model:  # å¦‚æœä½ç½®è¯¯å·®æ²¡æ”¹å–„ä½†æŸå¤±æ”¹å–„äº†ï¼Œä¹Ÿä¿å­˜
                    save_model = True

            if save_model:
                best_path = os.path.join(config.checkpoint_dir, 'best_model.pth')
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'best_loss': best_val_loss,
                    'best_position_error': best_val_position_error,
                }, best_path)
                print(f"  ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹: {best_path}")
                print(f"     æœ€ä½³éªŒè¯ä½ç½®è¯¯å·®: {best_val_position_error:.4f}")
                print(f"     æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.4f}")
            else:
                patience_counter += 1
                print(f"  âš ï¸ éªŒè¯ä½ç½®è¯¯å·®æœªæ”¹å–„ ({patience_counter}/{early_stopping_patience})")
                print(f"     å½“å‰: {val_position_error:.4f}, æœ€ä½³: {best_val_position_error:.4f}")

            # æ—©åœæ£€æŸ¥ï¼šåŸºäºä½ç½®è¯¯å·®
            if patience_counter >= early_stopping_patience:
                print(f"\nâ¹ï¸ æ—©åœè§¦å‘ï¼éªŒè¯ä½ç½®è¯¯å·®å·²ç»{early_stopping_patience}ä¸ªepochæ²¡æœ‰æ”¹å–„")
                print(f"æœ€ä½³éªŒè¯ä½ç½®è¯¯å·®: {best_val_position_error:.4f}")
                print(f"æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.4f}")
                break

        # ä¿å­˜æ£€æŸ¥ç‚¹
        if epoch % config.save_interval == 0:
            checkpoint_path = os.path.join(
                config.checkpoint_dir,
                f'checkpoint_epoch_{epoch}.pth'
            )
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
            }, checkpoint_path)
            print(f"  ä¿å­˜æ£€æŸ¥ç‚¹: {checkpoint_path}")

        # è·å–å½“å‰å­¦ä¹ ç‡
        current_lr = optimizer.param_groups[0]['lr']

        # è®°å½•æ—¥å¿—
        epoch_log = {
            'epoch': epoch,
            'learning_rate': current_lr,
            'train': {
                'loss': epoch_loss,
                'position_error': epoch_position_error,
            },
        }
        if epoch % config.val_interval == 0:
            epoch_log['val'] = {
                'loss': val_loss,
                'position_error': val_position_error,
            }

        training_log['epochs'].append(epoch_log)

        # ä¿å­˜è®­ç»ƒæ—¥å¿—
        log_path = os.path.join(config.log_dir, 'training_log.json')
        with open(log_path, 'w') as f:
            json.dump(training_log, f, indent=2)

        # å­¦ä¹ ç‡è¡°å‡ï¼ˆæ¯ä¸ªepochç»“æŸåï¼‰
        scheduler.step()

    print("\nè®­ç»ƒå®Œæˆï¼")
    print(f"æœ€ä½³éªŒè¯æŸå¤±: {best_loss:.4f}")
    print(f"\nä¸‹ä¸€æ­¥ï¼šä½¿ç”¨ visualize_mamba_agent.py å¯è§†åŒ–ç»“æœ")


if __name__ == '__main__':
    train()
