"""
Mamba-Adaptiveæ‰«æè·¯å¾„æ¨¡å‹è®­ç»ƒè„šæœ¬
ç»“åˆ Mamba + AdaptiveNN Focusæœºåˆ¶
"""
import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import json
from datetime import datetime
from tqdm import tqdm
from pathlib import Path

from config_mamba_adaptive import MambaAdaptiveConfig
from data.dataset import create_dataloaders
from models.mamba_adaptive_scanpath import MambaAdaptiveScanpath
import math


def compute_teacher_forcing_ratio(epoch, step_idx=None):
    """
    æŒ‡æ•°è¡°å‡çš„Teacher Forcingç­–ç•¥

    Args:
        epoch: å½“å‰è®­ç»ƒè½®æ¬¡
        step_idx: å½“å‰åºåˆ—ä¸­çš„æ­¥éª¤ç´¢å¼•ï¼ˆ0-29ï¼‰ï¼Œç”¨äºå‰å‡ æ­¥ä¿æŒé«˜TF
    """
    initial_ratio = 0.7
    final_ratio = 0.2  # ä»0.1æé«˜åˆ°0.2
    decay_epochs = 150  # ä»100å»¶é•¿åˆ°150

    # æŒ‡æ•°è¡°å‡: ratio = 0.7 * exp(-k * epoch)
    k = -math.log(final_ratio / initial_ratio) / decay_epochs
    base_ratio = initial_ratio * math.exp(-k * epoch)
    base_ratio = max(base_ratio, final_ratio)

    # å‰5æ­¥ä¿æŒæ›´é«˜çš„Teacher Forcingï¼Œç¡®ä¿åºåˆ—èµ·å§‹å¯¹é½
    if step_idx is not None and step_idx < 5:
        return min(base_ratio + 0.3, 0.95)

    return base_ratio


def compute_spatial_coverage_loss(pred_scanpaths):
    """åˆå¹¶è¦†ç›–èŒƒå›´ã€å¤šæ ·æ€§å’Œä¸­å¿ƒèšé›†æƒ©ç½š"""
    # è¦†ç›–èŒƒå›´
    pred_min = pred_scanpaths.min(dim=1)[0]
    pred_max = pred_scanpaths.max(dim=1)[0]
    pred_range = pred_max - pred_min

    coverage_x = torch.mean(((0.3 - pred_range[:, 0]).clamp(min=0.0)) ** 2)
    coverage_y = torch.mean(((0.25 - pred_range[:, 1]).clamp(min=0.0)) ** 2)

    # å¤šæ ·æ€§
    pred_mean = pred_scanpaths.mean(dim=1)
    pred_var = ((pred_scanpaths - pred_mean.unsqueeze(1)) ** 2).mean(dim=1)

    diversity_x = torch.mean(((0.015 - pred_var[:, 0]).clamp(min=0.0)) ** 2)
    diversity_y = torch.mean(((0.025 - pred_var[:, 1]).clamp(min=0.0)) ** 2)

    # Yæ–¹å‘ä¸­å¿ƒèšé›†æƒ©ç½šï¼ˆä¿®å¤ï¼šæƒ©ç½šåç¦»0.5çš„ä»»ä½•æ–¹å‘ï¼‰
    y_center_dist = torch.abs(pred_mean[:, 1] - 0.5)
    # å…è®¸Â±0.05çš„åå·®ï¼Œè¶…å‡ºåˆ™æƒ©ç½šï¼ˆä¿®å¤y_mean=0.61çš„é—®é¢˜ï¼‰
    y_bias_penalty = torch.mean((y_center_dist - 0.05).clamp(min=0.0) ** 2)

    # å†…éƒ¨åŠ æƒç»„åˆ
    return coverage_x + 3.0*coverage_y + diversity_x + 5.0*diversity_y + 15.0*y_bias_penalty


def compute_trajectory_smoothness_loss(pred_scanpaths, true_scanpaths):
    """åˆå¹¶æ­¥é•¿ã€è·³è·ƒå’ŒåŠ é€Ÿåº¦çº¦æŸ"""
    pred_diffs = pred_scanpaths[:, 1:] - pred_scanpaths[:, :-1]
    true_diffs = true_scanpaths[:, 1:] - true_scanpaths[:, :-1]

    pred_steps = torch.norm(pred_diffs, p=2, dim=-1)
    true_steps = torch.norm(true_diffs, p=2, dim=-1)

    # æ­¥é•¿åŒ¹é…
    step_loss = F.mse_loss(pred_steps, true_steps)

    # è·³è·ƒæƒ©ç½š
    jump_loss = torch.mean((pred_steps - 0.2).clamp(min=0.0) ** 2)

    # åŠ é€Ÿåº¦çº¦æŸ
    if pred_steps.shape[1] > 1:
        pred_accel = pred_steps[:, 1:] - pred_steps[:, :-1]
        true_accel = true_steps[:, 1:] - true_steps[:, :-1]
        accel_loss = F.mse_loss(pred_accel, true_accel)
    else:
        accel_loss = torch.tensor(0.0, device=pred_scanpaths.device)

    return step_loss + 0.5*jump_loss + 0.3*accel_loss


def compute_direction_consistency_loss(pred_scanpaths, true_scanpaths):
    """åˆå¹¶æ–¹å‘å˜åŒ–å’Œæ–¹å‘è¿ç»­æ€§"""
    pred_diffs = pred_scanpaths[:, 1:] - pred_scanpaths[:, :-1]
    true_diffs = true_scanpaths[:, 1:] - true_scanpaths[:, :-1]

    pred_steps = torch.norm(pred_diffs, p=2, dim=-1, keepdim=True)
    true_steps = torch.norm(true_diffs, p=2, dim=-1, keepdim=True)

    pred_directions = pred_diffs / (pred_steps + 1e-8)
    true_directions = true_diffs / (true_steps + 1e-8)

    # æ–¹å‘å˜åŒ–
    if pred_directions.shape[1] > 1:
        pred_dir_diffs = pred_directions[:, 1:] - pred_directions[:, :-1]
        true_dir_diffs = true_directions[:, 1:] - true_directions[:, :-1]
        direction_loss = F.mse_loss(
            torch.norm(pred_dir_diffs, p=2, dim=-1),
            torch.norm(true_dir_diffs, p=2, dim=-1)
        )
    else:
        direction_loss = torch.tensor(0.0, device=pred_scanpaths.device)

    # æ–¹å‘è¿ç»­æ€§
    if pred_directions.shape[1] > 0:
        pred_similarity = F.cosine_similarity(pred_directions[:, :-1], pred_directions[:, 1:], dim=-1)
        true_similarity = F.cosine_similarity(true_directions[:, :-1], true_directions[:, 1:], dim=-1)
        continuity_loss = F.mse_loss(pred_similarity, true_similarity)
    else:
        continuity_loss = torch.tensor(0.0, device=pred_scanpaths.device)

    return direction_loss + continuity_loss


def compute_sequence_alignment_loss(pred_scanpaths, true_scanpaths):
    """
    åºåˆ—å¯¹é½æŸå¤±ï¼šé¼“åŠ±é¢„æµ‹åºåˆ—ä¸çœŸå®åºåˆ—åœ¨æ—¶é—´ä¸Šå¯¹é½
    å‰å‡ æ­¥ç»™äºˆæ›´é«˜æƒé‡ï¼Œç¡®ä¿èµ·å§‹ç‚¹å’Œæ—©æœŸè½¨è¿¹åŒ¹é…
    """
    B, T, D = pred_scanpaths.shape

    # è®¡ç®—æ¯ä¸ªé¢„æµ‹ç‚¹ä¸å¯¹åº”çœŸå®ç‚¹çš„è·ç¦»
    point_distances = torch.norm(pred_scanpaths - true_scanpaths, dim=-1)  # (B, T)

    # å‰å‡ æ­¥ç»™äºˆæ›´é«˜æƒé‡ï¼ˆå¯¹LEVæŒ‡æ ‡è‡³å…³é‡è¦ï¼‰
    weights = torch.ones(T, device=pred_scanpaths.device)
    weights[:5] = 5.0   # å‰5æ­¥æƒé‡x5ï¼ˆèµ·å§‹ç‚¹å¯¹é½ï¼‰
    weights[5:10] = 3.0  # 5-10æ­¥æƒé‡x3
    weights[10:15] = 2.0  # 10-15æ­¥æƒé‡x2

    # åŠ æƒå¹³å‡
    alignment_loss = torch.mean(point_distances * weights.unsqueeze(0))

    return alignment_loss


def train():
    """è®­ç»ƒä¸»å‡½æ•°"""
    config = MambaAdaptiveConfig()

    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(config.log_dir, exist_ok=True)
    os.makedirs(config.checkpoint_dir, exist_ok=True)

    # åŠ è½½æ•°æ®
    print("åŠ è½½æ•°æ®...")
    train_loader, test_loader = create_dataloaders(config)
    print(f"è®­ç»ƒé›†: {len(train_loader)} batches")
    print(f"æµ‹è¯•é›†: {len(test_loader)} batches")

    # åˆ›å»ºæ¨¡å‹
    print("\nåˆ›å»ºMamba-Adaptiveæ¨¡å‹ï¼ˆç»“åˆFocusæœºåˆ¶ï¼‰...")
    model = MambaAdaptiveScanpath(config).to(config.device)
    print(f"æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters()) / 1e6:.2f}M")

    # ä¼˜åŒ–å™¨
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=config.learning_rate,
        weight_decay=config.weight_decay
    )

    # å­¦ä¹ ç‡è°ƒåº¦å™¨ - ä½¿ç”¨ä½™å¼¦é€€ç«ï¼ˆæ›´å¥½çš„æ”¶æ•›æ€§ï¼‰
    # è®­ç»ƒç›®æ ‡ï¼šå­¦ä¹ ç‡åœ¨å‰åŠç¨‹è¾ƒé«˜ï¼ˆå¿«é€Ÿå­¦ä¹ ï¼‰ï¼ŒååŠç¨‹è¾ƒä½ï¼ˆç²¾ç»†è°ƒä¼˜ï¼‰
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer,
        T_max=config.num_epochs,
        eta_min=config.learning_rate * 0.01  # æœ€å°å­¦ä¹ ç‡ä¸ºåˆå§‹çš„1%
    )

    # æ—©åœæœºåˆ¶ï¼šåŸºäºéªŒè¯ä½ç½®è¯¯å·®è€Œä¸æ˜¯æŸå¤±
    # æ”¹è¿›ï¼šä½¿ç”¨ä½ç½®è¯¯å·®ä½œä¸ºæ—©åœæŒ‡æ ‡ï¼Œæ›´ç¬¦åˆä¸»è¦ç›®æ ‡
    best_val_position_error = float('inf')
    patience_counter = 0
    early_stopping_patience = 20  # å¢åŠ åˆ°20ï¼Œç»™æ¨¡å‹æ›´å¤šæœºä¼š
    best_val_loss = float('inf')  # ä»ç„¶è®°å½•ï¼Œä½†ç”¨äºä¿å­˜æ¨¡å‹

    # è®­ç»ƒæ—¥å¿—
    training_log = {
        'config': {
            'seq_len': config.seq_len,
            'batch_size': config.batch_size,
            'learning_rate': config.learning_rate,
            'num_epochs': config.num_epochs,
            'feature_dim': config.feature_dim,
            'd_state': config.d_state,
            'focus_patch_size': config.focus_patch_size,
        },
        'epochs': []
    }

    # è®­ç»ƒå¾ªç¯
    print("\nå¼€å§‹è®­ç»ƒ...")
    best_loss = float('inf')

    for epoch in range(1, config.num_epochs + 1):
        print(f"\n{'='*80}")
        print(f"Epoch {epoch}/{config.num_epochs}")
        print(f"{'='*80}")

        # è®­ç»ƒ
        model.train()
        epoch_loss = 0
        epoch_position_error = 0

        train_bar = tqdm(train_loader, desc="è®­ç»ƒ")
        for batch_idx, batch in enumerate(train_bar):
            images = batch['image'].to(config.device)
            true_scanpaths = batch['scanpath'].to(config.device)

            # å‰å‘ä¼ æ’­ - ä¼ é€’çœŸå®ä½ç½®ç”¨äºTeacher Forcing
            # æ”¹è¿›Teacher Forcingç­–ç•¥ï¼šæŒ‡æ•°è¡°å‡
            teacher_forcing_ratio = compute_teacher_forcing_ratio(epoch)

            # è®­ç»ƒæ—¶æ˜¾å¼è®¾ç½®enable_early_stop=Falseï¼Œç¡®ä¿è¿”å›3ä¸ªå€¼
            # use_gt_start=True ç¡®ä¿ä½¿ç”¨çœŸå®èµ·å§‹ç‚¹ï¼Œæ”¹å–„LEVæŒ‡æ ‡
            predicted_scanpaths, mus, logvars = model(
                images,
                gt_scanpaths=true_scanpaths,
                teacher_forcing_ratio=teacher_forcing_ratio,
                enable_early_stop=False,
                use_gt_start=True  # ä½¿ç”¨çœŸå®èµ·å§‹ç‚¹
            )

            # ========== ç®€åŒ–æŸå¤±å‡½æ•°ï¼ˆ13é¡¹ -> 7é¡¹ï¼‰==========
            # 1. é‡æ„æŸå¤±ï¼ˆå‡†ç¡®åŒ¹é…çœŸå®è·¯å¾„ï¼‰
            reconstruction_loss = nn.functional.mse_loss(predicted_scanpaths, true_scanpaths)

            # 2. KLæ•£åº¦æ­£åˆ™åŒ–ï¼ˆé˜²æ­¢è¿‡æ‹Ÿåˆï¼‰
            kl_loss = -0.5 * torch.sum(1 + logvars - mus.pow(2) - logvars.exp())
            kl_loss = kl_loss / (mus.size(0) * mus.size(1))  # å½’ä¸€åŒ–

            # 3. ç©ºé—´è¦†ç›–æŸå¤±ï¼ˆåˆå¹¶coverage + diversity + center_penaltyï¼‰
            spatial_coverage_loss = compute_spatial_coverage_loss(predicted_scanpaths)

            # 4. è½¨è¿¹å¹³æ»‘æŸå¤±ï¼ˆåˆå¹¶step_length + jump_penalty + accelerationï¼‰
            trajectory_smoothness_loss = compute_trajectory_smoothness_loss(predicted_scanpaths, true_scanpaths)

            # 5. æ–¹å‘ä¸€è‡´æ€§æŸå¤±ï¼ˆåˆå¹¶direction + direction_continuityï¼‰
            direction_consistency_loss = compute_direction_consistency_loss(predicted_scanpaths, true_scanpaths)

            # 6. åºåˆ—å¯¹é½æŸå¤±ï¼ˆæ–°å¢ï¼šæ”¹å–„LEVæŒ‡æ ‡ï¼‰
            sequence_alignment_loss = compute_sequence_alignment_loss(predicted_scanpaths, true_scanpaths)

            # 7. è¾¹ç•Œçº¦æŸ
            boundary_min = 0.02
            boundary_max = 0.98
            below_boundary = (predicted_scanpaths < boundary_min).float()
            above_boundary = (predicted_scanpaths > boundary_max).float()
            boundary_penalty = torch.mean(
                below_boundary * (boundary_min - predicted_scanpaths) ** 2 +
                above_boundary * (predicted_scanpaths - boundary_max) ** 2
            )

            # ========== æ”¹è¿›çš„æƒé‡è°ƒåº¦ ==========
            if epoch <= 80:
                weights = {
                    'reconstruction': 2.0,  # æé«˜ï¼ˆä»1.0åˆ°2.0ï¼‰
                    'kl': 0.001,            # é™ä½ï¼ˆä»0.005åˆ°0.001ï¼‰
                    'spatial_coverage': 0.5,
                    'trajectory_smoothness': 1.5,
                    'direction_consistency': 0.5,
                    'sequence_alignment': 2.0,  # æ–°å¢ï¼šé«˜æƒé‡æ”¹å–„LEV
                    'boundary': 0.2
                }
            elif epoch <= 150:
                progress = (epoch - 80) / 70.0
                weights = {
                    'reconstruction': 2.0,
                    'kl': 0.001,
                    'spatial_coverage': 0.5 + 0.3*progress,
                    'trajectory_smoothness': 1.5,
                    'direction_consistency': 0.5,
                    'sequence_alignment': 2.0 + 1.0*progress,  # é€æ¸å¢åŠ åˆ°3.0
                    'boundary': 0.2
                }
            else:
                weights = {
                    'reconstruction': 2.0,
                    'kl': 0.001,
                    'spatial_coverage': 0.8,
                    'trajectory_smoothness': 1.5,
                    'direction_consistency': 0.5,
                    'sequence_alignment': 3.0,  # æœ€ç»ˆé«˜æƒé‡
                    'boundary': 0.2
                }

            # è®¡ç®—æ€»æŸå¤±
            loss = (
                weights['reconstruction'] * reconstruction_loss +
                weights['kl'] * kl_loss +
                weights['spatial_coverage'] * spatial_coverage_loss +
                weights['trajectory_smoothness'] * trajectory_smoothness_loss +
                weights['direction_consistency'] * direction_consistency_loss +
                weights['sequence_alignment'] * sequence_alignment_loss +
                weights['boundary'] * boundary_penalty
            )

            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()

            # è®¡ç®—ä½ç½®è¯¯å·®
            position_weights_error = torch.ones(config.seq_len, device=predicted_scanpaths.device)
            if epoch <= 80:
                position_weights_error[0] = 2.5
                position_weights_error[1:5] = 1.8
                position_weights_error[5:10] = 1.3
            else:
                position_weights_error[0] = 2.0
                position_weights_error[1:5] = 1.5
                position_weights_error[5:10] = 1.2
            
            # åŠ æƒä½ç½®è¯¯å·®
            weighted_errors = torch.norm(
                predicted_scanpaths - true_scanpaths,
                dim=-1
            ) * position_weights_error.unsqueeze(0)
            position_error = weighted_errors.mean() / position_weights_error.mean()  # å½’ä¸€åŒ–ä»¥ä¿æŒåŸæœ‰å°ºåº¦

            # ç´¯ç§¯æŒ‡æ ‡
            epoch_loss += loss.item()
            epoch_position_error += position_error.item()

            # æ›´æ–°è¿›åº¦æ¡
            if (batch_idx + 1) % config.log_interval == 0:
                avg_loss = epoch_loss / (batch_idx + 1)
                avg_error = epoch_position_error / (batch_idx + 1)
                train_bar.set_postfix({
                    'Loss': f"{avg_loss:.4f}",
                    'PosErr': f"{avg_error:.4f}",
                    'TF': f"{teacher_forcing_ratio:.3f}",
                    'SeqAlign': f"{sequence_alignment_loss.item():.4f}",
                    'SpatCov': f"{spatial_coverage_loss.item():.4f}",
                })

        # å¹³å‡è®­ç»ƒæŒ‡æ ‡
        num_batches = len(train_loader)
        epoch_loss /= num_batches
        epoch_position_error /= num_batches

        # æ‰“å°è®­ç»ƒç»“æœ
        print(f"\nè®­ç»ƒç»“æœ:")
        print(f"  Loss: {epoch_loss:.4f}")
        print(f"  PositionError: {epoch_position_error:.4f}")

        # éªŒè¯
        if epoch % config.val_interval == 0:
            print(f"\néªŒè¯...")
            model.eval()
            val_loss = 0
            val_position_error = 0

            val_bar = tqdm(test_loader, desc="éªŒè¯")
            with torch.no_grad():
                for batch in val_bar:
                    images = batch['image'].to(config.device)
                    true_scanpaths = batch['scanpath'].to(config.device)

                    # å‰å‘ä¼ æ’­ - éªŒè¯æ¨¡å¼
                    # ä½¿ç”¨è¾ƒä½çš„Teacher Forcingï¼Œæ›´æ¥è¿‘æ¨ç†æ—¶çš„0.0
                    val_teacher_forcing = max(0.05, teacher_forcing_ratio * 0.3)
                    result = model(images, gt_scanpaths=true_scanpaths,
                                 teacher_forcing_ratio=val_teacher_forcing,
                                 enable_early_stop=False,
                                 use_gt_start=True)  # éªŒè¯æ—¶ä¹Ÿä½¿ç”¨çœŸå®èµ·å§‹ç‚¹
                    # å®‰å…¨è§£åŒ…ï¼šæ— è®ºè¿”å›3ä¸ªè¿˜æ˜¯5ä¸ªå€¼ï¼Œéƒ½åªå–å‰3ä¸ª
                    predicted_scanpaths = result[0]
                    mus = result[1]
                    logvars = result[2]

                    # ========== ç®€åŒ–éªŒè¯æŸå¤±ï¼ˆä¸è®­ç»ƒä¸€è‡´ï¼‰==========
                    # 1. é‡æ„æŸå¤±
                    reconstruction_loss = nn.functional.mse_loss(predicted_scanpaths, true_scanpaths)

                    # 2. KLæ•£åº¦æ­£åˆ™åŒ–
                    kl_loss = -0.5 * torch.sum(1 + logvars - mus.pow(2) - logvars.exp())
                    kl_loss = kl_loss / (mus.size(0) * mus.size(1))

                    # 3. ç©ºé—´è¦†ç›–æŸå¤±
                    spatial_coverage_loss = compute_spatial_coverage_loss(predicted_scanpaths)

                    # 4. è½¨è¿¹å¹³æ»‘æŸå¤±
                    trajectory_smoothness_loss = compute_trajectory_smoothness_loss(predicted_scanpaths, true_scanpaths)

                    # 5. æ–¹å‘ä¸€è‡´æ€§æŸå¤±
                    direction_consistency_loss = compute_direction_consistency_loss(predicted_scanpaths, true_scanpaths)

                    # 6. åºåˆ—å¯¹é½æŸå¤±
                    sequence_alignment_loss = compute_sequence_alignment_loss(predicted_scanpaths, true_scanpaths)

                    # 7. è¾¹ç•Œçº¦æŸ
                    boundary_min = 0.02
                    boundary_max = 0.98
                    below_boundary = (predicted_scanpaths < boundary_min).float()
                    above_boundary = (predicted_scanpaths > boundary_max).float()
                    boundary_penalty = torch.mean(
                        below_boundary * (boundary_min - predicted_scanpaths) ** 2 +
                        above_boundary * (predicted_scanpaths - boundary_max) ** 2
                    )

                    # ä½¿ç”¨ä¸è®­ç»ƒç›¸åŒçš„æƒé‡
                    if epoch <= 80:
                        weights = {
                            'reconstruction': 2.0,
                            'kl': 0.001,
                            'spatial_coverage': 0.5,
                            'trajectory_smoothness': 1.5,
                            'direction_consistency': 0.5,
                            'sequence_alignment': 2.0,
                            'boundary': 0.2
                        }
                    elif epoch <= 150:
                        progress = (epoch - 80) / 70.0
                        weights = {
                            'reconstruction': 2.0,
                            'kl': 0.001,
                            'spatial_coverage': 0.5 + 0.3*progress,
                            'trajectory_smoothness': 1.5,
                            'direction_consistency': 0.5,
                            'sequence_alignment': 2.0 + 1.0*progress,
                            'boundary': 0.2
                        }
                    else:
                        weights = {
                            'reconstruction': 2.0,
                            'kl': 0.001,
                            'spatial_coverage': 0.8,
                            'trajectory_smoothness': 1.5,
                            'direction_consistency': 0.5,
                            'sequence_alignment': 3.0,
                            'boundary': 0.2
                        }

                    # è®¡ç®—æ€»æŸå¤±
                    loss = (
                        weights['reconstruction'] * reconstruction_loss +
                        weights['kl'] * kl_loss +
                        weights['spatial_coverage'] * spatial_coverage_loss +
                        weights['trajectory_smoothness'] * trajectory_smoothness_loss +
                        weights['direction_consistency'] * direction_consistency_loss +
                        weights['sequence_alignment'] * sequence_alignment_loss +
                        weights['boundary'] * boundary_penalty
                    )

                    # è®¡ç®—ä½ç½®è¯¯å·®
                    position_error = torch.norm(
                        predicted_scanpaths - true_scanpaths,
                        dim=-1
                    ).mean()

                    val_loss += loss.item()
                    val_position_error += position_error.item()

            # å¹³å‡éªŒè¯æŒ‡æ ‡
            num_val_batches = len(test_loader)
            val_loss /= num_val_batches
            val_position_error /= num_val_batches

            print(f"\néªŒè¯ç»“æœ:")
            print(f"  Loss: {val_loss:.4f}")
            print(f"  PositionError: {val_position_error:.4f}")

            # å­¦ä¹ ç‡è°ƒåº¦ - ExponentialLRåœ¨æ¯ä¸ªepochåè‡ªåŠ¨è¡°å‡
            current_lr = optimizer.param_groups[0]['lr']
            print(f"  Learning Rate: {current_lr:.6f}")

            # ä¿å­˜æœ€ä½³æ¨¡å‹ï¼šä¼˜å…ˆåŸºäºä½ç½®è¯¯å·®ï¼Œä¹Ÿè€ƒè™‘æŸå¤±
            save_model = False
            if val_position_error < best_val_position_error:
                best_val_position_error = val_position_error
                save_model = True
                patience_counter = 0  # é‡ç½®æ—©åœè®¡æ•°å™¨ï¼ˆåŸºäºä½ç½®è¯¯å·®ï¼‰
                print(f"  âœ… éªŒè¯ä½ç½®è¯¯å·®æ”¹å–„: {val_position_error:.4f} (æ–°æœ€ä½³)")
            
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                if not save_model:  # å¦‚æœä½ç½®è¯¯å·®æ²¡æ”¹å–„ä½†æŸå¤±æ”¹å–„äº†ï¼Œä¹Ÿä¿å­˜
                    save_model = True
            
            if save_model:
                best_path = os.path.join(config.checkpoint_dir, 'best_model.pth')
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'best_loss': best_val_loss,
                    'best_position_error': best_val_position_error,
                }, best_path)
                print(f"  ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹: {best_path}")
                print(f"     æœ€ä½³éªŒè¯ä½ç½®è¯¯å·®: {best_val_position_error:.4f}")
                print(f"     æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.4f}")
            else:
                patience_counter += 1
                print(f"  âš ï¸ éªŒè¯ä½ç½®è¯¯å·®æœªæ”¹å–„ ({patience_counter}/{early_stopping_patience})")
                print(f"     å½“å‰: {val_position_error:.4f}, æœ€ä½³: {best_val_position_error:.4f}")

            # æ—©åœæ£€æŸ¥ï¼šåŸºäºä½ç½®è¯¯å·®
            if patience_counter >= early_stopping_patience:
                print(f"\nâ¹ï¸ æ—©åœè§¦å‘ï¼éªŒè¯ä½ç½®è¯¯å·®å·²ç»{early_stopping_patience}ä¸ªepochæ²¡æœ‰æ”¹å–„")
                print(f"æœ€ä½³éªŒè¯ä½ç½®è¯¯å·®: {best_val_position_error:.4f}")
                print(f"æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.4f}")
                break

        # ä¿å­˜æ£€æŸ¥ç‚¹
        if epoch % config.save_interval == 0:
            checkpoint_path = os.path.join(
                config.checkpoint_dir,
                f'checkpoint_epoch_{epoch}.pth'
            )
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
            }, checkpoint_path)
            print(f"  ä¿å­˜æ£€æŸ¥ç‚¹: {checkpoint_path}")

        # è·å–å½“å‰å­¦ä¹ ç‡
        current_lr = optimizer.param_groups[0]['lr']

        # è®°å½•æ—¥å¿—
        epoch_log = {
            'epoch': epoch,
            'learning_rate': current_lr,
            'train': {
                'loss': epoch_loss,
                'position_error': epoch_position_error,
            },
        }
        if epoch % config.val_interval == 0:
            epoch_log['val'] = {
                'loss': val_loss,
                'position_error': val_position_error,
            }

        training_log['epochs'].append(epoch_log)

        # ä¿å­˜è®­ç»ƒæ—¥å¿—
        log_path = os.path.join(config.log_dir, 'training_log.json')
        with open(log_path, 'w') as f:
            json.dump(training_log, f, indent=2)

        # å­¦ä¹ ç‡è¡°å‡ï¼ˆæ¯ä¸ªepochç»“æŸåï¼‰
        scheduler.step()

    print("\nè®­ç»ƒå®Œæˆï¼")
    print(f"æœ€ä½³éªŒè¯æŸå¤±: {best_loss:.4f}")
    print(f"\nä¸‹ä¸€æ­¥ï¼šä½¿ç”¨ visualize_mamba_agent.py å¯è§†åŒ–ç»“æœ")


if __name__ == '__main__':
    train()
