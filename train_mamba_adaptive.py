"""
Mamba-Adaptiveæ‰«æè·¯å¾„æ¨¡å‹è®­ç»ƒè„šæœ¬
ç»“åˆ Mamba + AdaptiveNN Focusæœºåˆ¶
"""
import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import json
from datetime import datetime
from tqdm import tqdm
from pathlib import Path

from config_mamba_adaptive import MambaAdaptiveConfig
from data.dataset import create_dataloaders
from models.mamba_adaptive_scanpath import MambaAdaptiveScanpath


def train():
    """è®­ç»ƒä¸»å‡½æ•°"""
    config = MambaAdaptiveConfig()

    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(config.log_dir, exist_ok=True)
    os.makedirs(config.checkpoint_dir, exist_ok=True)

    # åŠ è½½æ•°æ®
    print("åŠ è½½æ•°æ®...")
    train_loader, test_loader = create_dataloaders(config)
    print(f"è®­ç»ƒé›†: {len(train_loader)} batches")
    print(f"æµ‹è¯•é›†: {len(test_loader)} batches")

    # åˆ›å»ºæ¨¡å‹
    print("\nåˆ›å»ºMamba-Adaptiveæ¨¡å‹ï¼ˆç»“åˆFocusæœºåˆ¶ï¼‰...")
    model = MambaAdaptiveScanpath(config).to(config.device)
    print(f"æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters()) / 1e6:.2f}M")

    # ä¼˜åŒ–å™¨
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=config.learning_rate,
        weight_decay=config.weight_decay
    )

    # å­¦ä¹ ç‡è°ƒåº¦å™¨ - ä½¿ç”¨ä½™å¼¦é€€ç«ï¼ˆæ›´å¥½çš„æ”¶æ•›æ€§ï¼‰
    # è®­ç»ƒç›®æ ‡ï¼šå­¦ä¹ ç‡åœ¨å‰åŠç¨‹è¾ƒé«˜ï¼ˆå¿«é€Ÿå­¦ä¹ ï¼‰ï¼ŒååŠç¨‹è¾ƒä½ï¼ˆç²¾ç»†è°ƒä¼˜ï¼‰
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer,
        T_max=config.num_epochs,
        eta_min=config.learning_rate * 0.01  # æœ€å°å­¦ä¹ ç‡ä¸ºåˆå§‹çš„1%
    )

    # æ—©åœæœºåˆ¶ï¼šåŸºäºéªŒè¯ä½ç½®è¯¯å·®è€Œä¸æ˜¯æŸå¤±
    # æ”¹è¿›ï¼šä½¿ç”¨ä½ç½®è¯¯å·®ä½œä¸ºæ—©åœæŒ‡æ ‡ï¼Œæ›´ç¬¦åˆä¸»è¦ç›®æ ‡
    best_val_position_error = float('inf')
    patience_counter = 0
    early_stopping_patience = 20  # å¢åŠ åˆ°20ï¼Œç»™æ¨¡å‹æ›´å¤šæœºä¼š
    best_val_loss = float('inf')  # ä»ç„¶è®°å½•ï¼Œä½†ç”¨äºä¿å­˜æ¨¡å‹

    # è®­ç»ƒæ—¥å¿—
    training_log = {
        'config': {
            'seq_len': config.seq_len,
            'batch_size': config.batch_size,
            'learning_rate': config.learning_rate,
            'num_epochs': config.num_epochs,
            'feature_dim': config.feature_dim,
            'd_state': config.d_state,
            'focus_patch_size': config.focus_patch_size,
        },
        'epochs': []
    }

    # è®­ç»ƒå¾ªç¯
    print("\nå¼€å§‹è®­ç»ƒ...")
    best_loss = float('inf')

    for epoch in range(1, config.num_epochs + 1):
        print(f"\n{'='*80}")
        print(f"Epoch {epoch}/{config.num_epochs}")
        print(f"{'='*80}")

        # è®­ç»ƒ
        model.train()
        epoch_loss = 0
        epoch_position_error = 0

        train_bar = tqdm(train_loader, desc="è®­ç»ƒ")
        for batch_idx, batch in enumerate(train_bar):
            images = batch['image'].to(config.device)
            true_scanpaths = batch['scanpath'].to(config.device)

            # å‰å‘ä¼ æ’­ - ä¼ é€’çœŸå®ä½ç½®ç”¨äºTeacher Forcing
            # æ”¹è¿›Teacher Forcingç­–ç•¥ï¼šåˆ†é˜¶æ®µè°ƒæ•´ï¼Œä¸è®­ç»ƒé˜¶æ®µå¯¹é½
            # é˜¶æ®µ1: ä¿æŒé«˜Teacher Forcingï¼Œè®©æ¨¡å‹å……åˆ†å­¦ä¹ çœŸå®è·¯å¾„
            # é˜¶æ®µ2: é€æ¸é™ä½ï¼Œè®©æ¨¡å‹æ›´å¤šä¾èµ–è‡ªèº«é¢„æµ‹
            # é˜¶æ®µ3: è¿›ä¸€æ­¥é™ä½ï¼Œä½†ä¿æŒä¸€å®šæ¯”ä¾‹é¿å…åˆ†å¸ƒä¸åŒ¹é…
            if epoch <= 80:
                teacher_forcing_ratio = 0.8  # é˜¶æ®µ1ï¼šé«˜Teacher Forcingï¼ˆæé«˜ï¼ï¼‰
            elif epoch <= 150:
                # é˜¶æ®µ2ï¼šä»0.8é€æ¸é™åˆ°0.6
                progress = (epoch - 80) / 70.0
                teacher_forcing_ratio = 0.8 - 0.2 * progress
            else:
                # é˜¶æ®µ3ï¼šä¿æŒ0.6ï¼Œé¿å…è®­ç»ƒå’Œæ¨ç†åˆ†å¸ƒå·®å¼‚è¿‡å¤§
                teacher_forcing_ratio = 0.6

            # è®­ç»ƒæ—¶æ˜¾å¼è®¾ç½®enable_early_stop=Falseï¼Œç¡®ä¿è¿”å›3ä¸ªå€¼
            predicted_scanpaths, mus, logvars = model(
                images,
                gt_scanpaths=true_scanpaths,
                teacher_forcing_ratio=teacher_forcing_ratio,
                enable_early_stop=False
            )

            # è®¡ç®—æŸå¤±å‡½æ•° - VAEæ¡†æ¶ï¼šé‡æ„æŸå¤± + KLæ•£åº¦æ­£åˆ™åŒ–
            # 1. é‡æ„æŸå¤±ï¼ˆå‡†ç¡®åŒ¹é…çœŸå®è·¯å¾„ï¼‰
            # ä½¿ç”¨æ ‡å‡†MSEï¼ˆç”¨äºç›‘æ§ï¼‰ï¼Œå®é™…æŸå¤±ä½¿ç”¨åŠ æƒMSEï¼ˆè§ä¸‹æ–¹ï¼‰
            reconstruction_loss = nn.functional.mse_loss(predicted_scanpaths, true_scanpaths)

            # 2. KLæ•£åº¦æ­£åˆ™åŒ–ï¼ˆé˜²æ­¢è¿‡æ‹Ÿåˆï¼‰
            # KL(q(z|x) || p(z)) = -0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)
            kl_loss = -0.5 * torch.sum(1 + logvars - mus.pow(2) - logvars.exp())
            kl_loss = kl_loss / (mus.size(0) * mus.size(1))  # å½’ä¸€åŒ–

            # 3. Beta-VAEï¼šæ§åˆ¶KLæ•£åº¦çš„æƒé‡
            # è®­ç»ƒç›®æ ‡ï¼šä¿æŒVAEçš„éšæœºæ€§ï¼Œä½†ä¸å½±å“ä¸»è¦çš„ä½ç½®é¢„æµ‹ç²¾åº¦
            # ç­–ç•¥ï¼šä½¿ç”¨è¾ƒå°çš„betaå€¼ï¼Œè®©é‡æ„æŸå¤±å ä¸»å¯¼
            beta = min(0.01, 0.005 * (1.01 ** (epoch - 1)))  # ä»0.005å¼€å§‹ï¼Œæœ€å¤šåˆ°0.01

            # 4. è¦†ç›–èŒƒå›´æŸå¤±ï¼šé¼“åŠ±é¢„æµ‹è·¯å¾„è¦†ç›–æ•´ä¸ªå›¾åƒï¼Œé˜²æ­¢é›†ä¸­åœ¨ä¸­å¿ƒ
            # è®¡ç®—é¢„æµ‹è·¯å¾„çš„è¦†ç›–èŒƒå›´ï¼ˆxå’Œyæ–¹å‘åˆ†åˆ«è®¡ç®—ï¼‰
            pred_min = predicted_scanpaths.min(dim=1)[0]  # (B, 2)
            pred_max = predicted_scanpaths.max(dim=1)[0]  # (B, 2)
            pred_range = pred_max - pred_min  # (B, 2)
            # ç†æƒ³è¦†ç›–èŒƒå›´åº”è¯¥æ˜¯æ¥è¿‘[1.0, 1.0]ï¼Œæƒ©ç½šå°èŒƒå›´
            # æ”¹è¿›ï¼šä½¿ç”¨æ›´æ•æ„Ÿçš„æƒ©ç½šï¼Œæé«˜é˜ˆå€¼åˆ°0.5ï¼Œå¹¶å¢åŠ æƒ©ç½šå¼ºåº¦
            coverage_loss = torch.mean(((0.5 - pred_range).clamp(min=0.0)) ** 2) * 2.0  # å¢åŠ 2å€æƒ©ç½š
            
            # 5. ä½ç½®å¤šæ ·æ€§æŸå¤±ï¼šé¼“åŠ±é¢„æµ‹ä½ç½®å…·æœ‰è¶³å¤Ÿçš„æ–¹å·®
            pred_mean = predicted_scanpaths.mean(dim=1)  # (B, 2)
            pred_var = ((predicted_scanpaths - pred_mean.unsqueeze(1)) ** 2).mean(dim=1)  # (B, 2)
            # æ”¹è¿›ï¼šæé«˜æ–¹å·®é˜ˆå€¼åˆ°0.03ï¼ˆä»0.02ï¼‰ï¼Œå¯¹åº”æ ‡å‡†å·®çº¦0.17ï¼Œå¢åŠ æƒ©ç½šå¼ºåº¦
            min_var = 0.03  # æœŸæœ›æœ€å°æ–¹å·®ï¼ˆå¯¹åº”æ ‡å‡†å·®çº¦0.17ï¼‰
            diversity_loss = torch.mean(((min_var - pred_var).clamp(min=0.0)) ** 2) * 3.0  # å¢åŠ 3å€æƒ©ç½š
            
            # 6. ä¸­å¿ƒèšé›†æƒ©ç½šï¼šæƒ©ç½šé¢„æµ‹å‡å€¼è¿‡äºæ¥è¿‘å›¾åƒä¸­å¿ƒ(0.5, 0.5)
            # é—®é¢˜ï¼š360åº¦å…¨æ™¯å›¾è·¯å¾„é›†ä¸­åœ¨ä¸­å¿ƒåŒºåŸŸï¼Œéœ€è¦å¼ºåˆ¶åˆ†æ•£
            # è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„å‡å€¼è·ç¦»ä¸­å¿ƒçš„è·ç¦»
            mean_center_dist = torch.mean((pred_mean - 0.5) ** 2, dim=-1)  # (B,)
            
            # æ”¹è¿›çš„æƒ©ç½šç­–ç•¥ï¼šæ›´ä¸¥æ ¼çš„æƒ©ç½š
            # 1. å½“è·ç¦»<0.03æ—¶ï¼ˆå‡å€¼åœ¨[0.43, 0.57]ï¼‰ï¼Œç»™äºˆå¼ºæƒ©ç½š
            # 2. å½“è·ç¦»<0.06æ—¶ï¼ˆå‡å€¼åœ¨[0.4, 0.6]ï¼‰ï¼Œç»™äºˆä¸­ç­‰æƒ©ç½š
            # 3. å½“è·ç¦»>=0.06æ—¶ï¼Œä¸ç»™æƒ©ç½š
            close_to_center = (mean_center_dist < 0.03).float()
            medium_distance = ((mean_center_dist >= 0.03) & (mean_center_dist < 0.06)).float()
            
            # å¼ºæƒ©ç½šï¼šè·ç¦»ä¸­å¿ƒå¾ˆè¿‘çš„ç‚¹ï¼ˆå¢åŠ æƒ©ç½šå¼ºåº¦ï¼‰
            strong_penalty = torch.mean(close_to_center * (0.03 - mean_center_dist) * 200.0)  # ä»100æé«˜åˆ°200
            # ä¸­ç­‰æƒ©ç½šï¼šè·ç¦»ä¸­å¿ƒè¾ƒè¿‘çš„ç‚¹ï¼ˆå¢åŠ æƒ©ç½šå¼ºåº¦ï¼‰
            medium_penalty = torch.mean(medium_distance * (0.06 - mean_center_dist) * 50.0)  # ä»20æé«˜åˆ°50
            
            center_penalty = strong_penalty + medium_penalty
            
            # é¢å¤–çš„ä¸­å¿ƒèšé›†æƒ©ç½šï¼šç›´æ¥æƒ©ç½šé¢„æµ‹ç‚¹é›†ä¸­åœ¨ä¸­å¿ƒåŒºåŸŸ
            # è®¡ç®—æ‰€æœ‰é¢„æµ‹ç‚¹åˆ°ä¸­å¿ƒçš„å¹³å‡è·ç¦»
            point_center_dist = torch.mean((predicted_scanpaths - 0.5) ** 2, dim=-1)  # (B, seq_len)
            # æ”¹è¿›ï¼šæé«˜é˜ˆå€¼åˆ°0.03ï¼Œå¢åŠ æƒ©ç½šå¼ºåº¦
            point_center_penalty = torch.mean(((0.03 - point_center_dist).clamp(min=0.0)) ** 2) * 100.0  # ä»50æé«˜åˆ°100

            # 7. è½¨è¿¹å¹³æ»‘æ€§æŸå¤±ï¼šé¼“åŠ±ç›¸é‚»ç‚¹ä¹‹é—´çš„è·ç¦»åˆç†ï¼Œä½¿è·¯å¾„è¿è´¯æµç•…
            # è®¡ç®—ç›¸é‚»ç‚¹ä¹‹é—´çš„æ­¥é•¿
            pred_diffs = predicted_scanpaths[:, 1:] - predicted_scanpaths[:, :-1]  # (B, seq_len-1, 2)
            true_diffs = true_scanpaths[:, 1:] - true_scanpaths[:, :-1]  # (B, seq_len-1, 2)
            
            # æ­¥é•¿è·ç¦»
            pred_step_lengths = torch.norm(pred_diffs, p=2, dim=-1)  # (B, seq_len-1)
            true_step_lengths = torch.norm(true_diffs, p=2, dim=-1)  # (B, seq_len-1)
            
            # å¹³æ»‘æ€§æŸå¤±1ï¼šç›¸é‚»ç‚¹è·ç¦»åº”è¯¥ä¸çœŸå®è·¯å¾„ç›¸ä¼¼
            step_length_loss = nn.functional.mse_loss(pred_step_lengths, true_step_lengths)
            
            # å¹³æ»‘æ€§æŸå¤±2ï¼šæƒ©ç½šè¿‡å¤§çš„è·³è·ƒï¼ˆé˜²æ­¢è·¯å¾„è¿‡äºåˆ†æ•£ï¼‰
            # çœŸå®è·¯å¾„çš„æ­¥é•¿é€šå¸¸å°äº0.15ï¼Œæƒ©ç½šè¶…è¿‡0.2çš„è·³è·ƒ
            max_reasonable_step = 0.20
            large_jumps = (pred_step_lengths - max_reasonable_step).clamp(min=0.0)  # åªæƒ©ç½šå¤§äº0.2çš„
            jump_penalty = torch.mean(large_jumps ** 2)
            
            # å¹³æ»‘æ€§æŸå¤±3ï¼šæ–¹å‘ä¸€è‡´æ€§ï¼ˆç›¸é‚»æ–¹å‘å˜åŒ–ä¸åº”è¯¥å¤ªå¤§ï¼‰
            # è®¡ç®—æ–¹å‘å‘é‡
            pred_directions = pred_diffs / (pred_step_lengths.unsqueeze(-1) + 1e-8)  # å½’ä¸€åŒ–æ–¹å‘
            true_directions = true_diffs / (true_step_lengths.unsqueeze(-1) + 1e-8)
            
            # è®¡ç®—ç›¸é‚»æ–¹å‘çš„ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆåº”è¯¥æ˜¯æ­£çš„ï¼Œè¡¨ç¤ºæ–¹å‘å˜åŒ–å¹³ç¼“ï¼‰
            if pred_directions.shape[1] > 1:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„ç‚¹è®¡ç®—æ–¹å‘å˜åŒ–
                pred_dir_diffs = pred_directions[:, 1:] - pred_directions[:, :-1]  # æ–¹å‘å˜åŒ–
                true_dir_diffs = true_directions[:, 1:] - true_directions[:, :-1]
                direction_loss = nn.functional.mse_loss(
                    torch.norm(pred_dir_diffs, p=2, dim=-1),
                    torch.norm(true_dir_diffs, p=2, dim=-1)
                )
            else:
                direction_loss = torch.tensor(0.0, device=predicted_scanpaths.device)
            
            # å¹³æ»‘æ€§æŸå¤±4ï¼šåŠ é€Ÿåº¦çº¦æŸï¼ˆæ­¥é•¿çš„å˜åŒ–åº”è¯¥å¹³æ»‘ï¼Œä¿è¯è·¯å¾„æµç•…ï¼‰
            # è®¡ç®—åŠ é€Ÿåº¦ï¼šç›¸é‚»æ­¥é•¿ä¹‹é—´çš„å˜åŒ–
            if pred_step_lengths.shape[1] > 1:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ­¥é•¿è®¡ç®—åŠ é€Ÿåº¦
                pred_acceleration = pred_step_lengths[:, 1:] - pred_step_lengths[:, :-1]  # (B, seq_len-2)
                true_acceleration = true_step_lengths[:, 1:] - true_step_lengths[:, :-1]
                acceleration_loss = nn.functional.mse_loss(pred_acceleration, true_acceleration)
            else:
                acceleration_loss = torch.tensor(0.0, device=predicted_scanpaths.device)
            
            # å¹³æ»‘æ€§æŸå¤±5ï¼šæ–¹å‘è¿ç»­æ€§ï¼ˆç›¸é‚»æ–¹å‘åº”è¯¥ç›¸ä¼¼ï¼Œé¿å…çªç„¶è½¬å‘ï¼‰
            if pred_directions.shape[1] > 0:
                # è®¡ç®—ç›¸é‚»æ–¹å‘çš„ä½™å¼¦ç›¸ä¼¼åº¦
                pred_dir_similarity = F.cosine_similarity(
                    pred_directions[:, :-1], 
                    pred_directions[:, 1:], 
                    dim=-1
                )  # (B, seq_len-2)
                true_dir_similarity = F.cosine_similarity(
                    true_directions[:, :-1], 
                    true_directions[:, 1:], 
                    dim=-1
                )
                direction_continuity_loss = nn.functional.mse_loss(
                    pred_dir_similarity, 
                    true_dir_similarity
                )
            else:
                direction_continuity_loss = torch.tensor(0.0, device=predicted_scanpaths.device)

            # ========== åˆ†é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼šä½ç½®ç²¾åº¦ä¼˜å…ˆ ==========
            # æ ¸å¿ƒé—®é¢˜ï¼šæ­£åˆ™åŒ–æƒé‡è¿‡é«˜å¯¼è‡´Epoch 80åä½ç½®è¯¯å·®çªç„¶ä¸Šå‡
            # è§£å†³æ–¹æ¡ˆï¼šåˆ†é˜¶æ®µè®­ç»ƒï¼Œå…ˆä¼˜åŒ–ä½ç½®ç²¾åº¦ï¼Œå†è€ƒè™‘åˆ†æ•£æ€§
            
            # é˜¶æ®µ1 (Epoch 1-80): åªä¼˜åŒ–ä½ç½®ç²¾åº¦ï¼Œä¸åŠ å…¥å¼ºæ­£åˆ™åŒ–
            # é˜¶æ®µ2 (Epoch 81-150): é€æ¸åŠ å…¥è½»å¾®æ­£åˆ™åŒ–ï¼Œä½†æƒé‡å¾ˆå°
            # é˜¶æ®µ3 (Epoch 151+): å¦‚æœä½ç½®è¯¯å·®è¶³å¤Ÿä½ï¼Œé€‚å½“å¢åŠ æ­£åˆ™åŒ–
            
            if epoch <= 80:
                # é˜¶æ®µ1ï¼šé‡æ„æŸå¤±å ä¸»å¯¼ï¼Œä½†å¿…é¡»ä¿è¯è·¯å¾„å¹³æ»‘æ€§å’Œåˆç†æ€§
                # æ”¹è¿›ï¼šå¢å¼ºåˆ†æ•£æ€§çº¦æŸï¼Œé˜²æ­¢è·¯å¾„èšé›†åœ¨ä¸­å¿ƒ
                coverage_weight = 0.15  # æé«˜è¦†ç›–èŒƒå›´çº¦æŸï¼ˆä»0.05æé«˜åˆ°0.15ï¼‰âš ï¸å…³é”®
                diversity_weight = 0.1  # åŠ å…¥å¤šæ ·æ€§æƒ©ç½šï¼ˆä»0æé«˜åˆ°0.1ï¼‰âš ï¸å…³é”®
                center_weight = 0.2  # å¢å¼ºä¸­å¿ƒèšé›†æƒ©ç½šï¼ˆä»0.05æé«˜åˆ°0.2ï¼‰âš ï¸å…³é”®
                point_center_weight = 0.15  # å¢å¼ºç‚¹ä¸­å¿ƒæƒ©ç½šï¼ˆä»0.03æé«˜åˆ°0.15ï¼‰âš ï¸å…³é”®
                smoothness_weight = 0.25  # ä¿æŒå¹³æ»‘æ€§æƒé‡
                jump_weight = 0.1  # ä¿æŒè·³è·ƒæƒ©ç½š
                direction_weight = 0.1  # ä¿æŒæ–¹å‘ä¸€è‡´æ€§
            elif epoch <= 150:
                # é˜¶æ®µ2ï¼šé€æ¸å¢åŠ æ­£åˆ™åŒ–ï¼Œä¿æŒé«˜å¹³æ»‘æ€§æƒé‡
                progress = (epoch - 80) / 70.0  # 0.0 -> 1.0
                coverage_weight = 0.05 + 0.1 * progress  # ä»0.05é€æ¸å¢åŠ åˆ°0.15
                diversity_weight = 0.05 * progress  # é€æ¸ä»0å¢åŠ åˆ°0.05
                center_weight = 0.05 + 0.1 * progress  # ä»0.05é€æ¸å¢åŠ åˆ°0.15
                point_center_weight = 0.03 + 0.05 * progress  # ä»0.03é€æ¸å¢åŠ åˆ°0.08
                smoothness_weight = 0.25 + 0.1 * progress  # ä»0.25å¢åŠ åˆ°0.35ï¼ˆä¿æŒé«˜æƒé‡ï¼‰
                jump_weight = 0.1 + 0.05 * progress  # ä»0.1å¢åŠ åˆ°0.15
                direction_weight = 0.1 + 0.05 * progress  # ä»0.1å¢åŠ åˆ°0.15
                acceleration_weight = 0.1 + 0.05 * progress  # åŠ é€Ÿåº¦çº¦æŸï¼šä»0.1å¢åŠ åˆ°0.15
                direction_continuity_weight = 0.1 + 0.05 * progress  # æ–¹å‘è¿ç»­æ€§ï¼šä»0.1å¢åŠ åˆ°0.15
            else:
                # é˜¶æ®µ3ï¼šå¹³è¡¡ä¼˜åŒ–ï¼Œä¿æŒé«˜å¹³æ»‘æ€§æƒé‡
                coverage_weight = 0.15  # ä¿æŒ0.15
                diversity_weight = 0.08  # ä¿æŒ0.08
                center_weight = 0.15  # ä¿æŒ0.15
                point_center_weight = 0.08  # ä¿æŒ0.08
                smoothness_weight = 0.35  # ä¿æŒé«˜æƒé‡ï¼ˆä»0.1æé«˜åˆ°0.35ï¼‰âš ï¸å…³é”®
                jump_weight = 0.15  # æé«˜ï¼ˆä»0.05æé«˜åˆ°0.15ï¼‰
                direction_weight = 0.15  # æé«˜ï¼ˆä»0.02æé«˜åˆ°0.15ï¼‰
                acceleration_weight = 0.15  # åŠ é€Ÿåº¦çº¦æŸ
                direction_continuity_weight = 0.15  # æ–¹å‘è¿ç»­æ€§
            
            # Batchå†…å¤šæ ·æ€§æŸå¤±ï¼šæ”¹è¿›ï¼šé˜¶æ®µ1ä¹Ÿä½¿ç”¨ï¼Œä½†æƒé‡è¾ƒå°
            batch_mean = predicted_scanpaths.mean(dim=0, keepdim=True)  # (1, seq_len, 2)
            batch_diversity = torch.mean((predicted_scanpaths - batch_mean) ** 2)  # æ ‡é‡
            min_batch_diversity = 0.015  # æé«˜é˜ˆå€¼ï¼ˆä»0.01åˆ°0.015ï¼‰
            batch_diversity_loss = torch.mean(((min_batch_diversity - batch_diversity).clamp(min=0.0)) ** 2)
            if epoch <= 80:
                batch_diversity_weight = 0.05  # é˜¶æ®µ1ä¹Ÿä½¿ç”¨ï¼Œæƒé‡0.05
            elif epoch <= 150:
                progress = (epoch - 80) / 70.0
                batch_diversity_weight = 0.05 + 0.05 * progress  # ä»0.05é€æ¸å¢åŠ åˆ°0.1
            else:
                batch_diversity_weight = 0.1  # é˜¶æ®µ3ä¿æŒ0.1
            
            # ä½¿ç”¨åŠ æƒMSEï¼šå¯¹èµ·å§‹ä½ç½®å’Œå‰å‡ æ­¥ç»™äºˆæ›´é«˜æƒé‡
            # ä¿®æ”¹ï¼šé™ä½æƒé‡ï¼Œé¿å…è¿‡åº¦å…³æ³¨å‰å‡ æ­¥è€Œå¿½ç•¥åç»­æ­¥éª¤
            position_weights = torch.ones(config.seq_len, device=predicted_scanpaths.device)
            if epoch <= 80:
                # é˜¶æ®µ1ï¼šé€‚åº¦æƒé‡ï¼Œå¹³è¡¡å‰åæ­¥éª¤
                position_weights[0] = 3.0  # èµ·å§‹ä½ç½®æƒé‡3å€ï¼ˆé™ä½ä»5.0ï¼‰
                position_weights[1:5] = 2.0  # å‰5æ­¥æƒé‡2å€ï¼ˆé™ä½ä»3.0ï¼‰
                position_weights[5:10] = 1.5  # 5-10æ­¥æƒé‡1.5å€ï¼ˆé™ä½ä»2.0ï¼‰
            else:
                # é˜¶æ®µ2å’Œ3ï¼šè¿›ä¸€æ­¥é™ä½æƒé‡ï¼Œæ›´å¹³è¡¡
                position_weights[0] = 2.0  # èµ·å§‹ä½ç½®æƒé‡2å€
                position_weights[1:5] = 1.5  # å‰5æ­¥æƒé‡1.5å€
                position_weights[5:10] = 1.2  # 5-10æ­¥æƒé‡1.2å€
            
            weighted_reconstruction_loss = torch.mean(
                position_weights.unsqueeze(0).unsqueeze(-1) * 
                (predicted_scanpaths - true_scanpaths) ** 2
            )
            
            # è®¡ç®—åŠ é€Ÿåº¦å’Œæ–¹å‘è¿ç»­æ€§æƒé‡ï¼ˆé˜¶æ®µ1ä¹Ÿéœ€è¦ï¼‰
            if epoch <= 80:
                acceleration_weight = 0.1  # é˜¶æ®µ1ï¼šåŠ é€Ÿåº¦çº¦æŸ
                direction_continuity_weight = 0.1  # é˜¶æ®µ1ï¼šæ–¹å‘è¿ç»­æ€§
            elif epoch <= 150:
                # å·²åœ¨ä¸Šé¢è®¡ç®—
                pass
            else:
                # å·²åœ¨ä¸Šé¢è®¡ç®—
                pass
            
            loss = weighted_reconstruction_loss + beta * kl_loss + \
                   coverage_weight * coverage_loss + \
                   diversity_weight * diversity_loss + \
                   center_weight * center_penalty + \
                   point_center_weight * point_center_penalty + \
                   smoothness_weight * step_length_loss + \
                   jump_weight * jump_penalty + \
                   direction_weight * direction_loss + \
                   acceleration_weight * acceleration_loss + \
                   direction_continuity_weight * direction_continuity_loss + \
                   batch_diversity_weight * batch_diversity_loss

            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()

            # è®¡ç®—ä½ç½®è¯¯å·® - ä½¿ç”¨åŠ æƒè¯¯å·®ï¼ˆä¸æŸå¤±å‡½æ•°ä¸€è‡´ï¼Œæ›´å‡†ç¡®åœ°åæ˜ æ¨¡å‹æ€§èƒ½ï¼‰
            # è®­ç»ƒç›®æ ‡ï¼šä½ç½®è¯¯å·®åº”è¯¥ä¸æŸå¤±å‡½æ•°åŒæ­¥æ”¹å–„
            # æƒé‡ä¸æŸå¤±å‡½æ•°ä¸­çš„position_weightsä¿æŒä¸€è‡´
            position_weights_error = torch.ones(config.seq_len, device=predicted_scanpaths.device)
            if epoch <= 80:
                position_weights_error[0] = 3.0  # ä¸æŸå¤±å‡½æ•°ä¸€è‡´
                position_weights_error[1:5] = 2.0
                position_weights_error[5:10] = 1.5
            else:
                position_weights_error[0] = 2.0
                position_weights_error[1:5] = 1.5
                position_weights_error[5:10] = 1.2
            
            # åŠ æƒä½ç½®è¯¯å·®
            weighted_errors = torch.norm(
                predicted_scanpaths - true_scanpaths,
                dim=-1
            ) * position_weights_error.unsqueeze(0)
            position_error = weighted_errors.mean() / position_weights_error.mean()  # å½’ä¸€åŒ–ä»¥ä¿æŒåŸæœ‰å°ºåº¦

            # ç´¯ç§¯æŒ‡æ ‡
            epoch_loss += loss.item()
            epoch_position_error += position_error.item()

            # æ›´æ–°è¿›åº¦æ¡
            if (batch_idx + 1) % config.log_interval == 0:
                avg_loss = epoch_loss / (batch_idx + 1)
                avg_error = epoch_position_error / (batch_idx + 1)
                avg_coverage = coverage_loss.item()
                avg_diversity = diversity_loss.item()
                avg_center = center_penalty.item()
                avg_smooth = step_length_loss.item()
                avg_jump = jump_penalty.item()
                avg_batch_div = batch_diversity_loss.item()
                avg_point_center = point_center_penalty.item()
                avg_acceleration = acceleration_loss.item()
                avg_dir_continuity = direction_continuity_loss.item()
                train_bar.set_postfix({
                    'Loss': f"{avg_loss:.4f}",
                    'PosErr': f"{avg_error:.4f}",
                    'Beta': f"{beta:.4f}",
                    'Cov': f"{avg_coverage:.4f}",
                    'Ctr': f"{avg_center:.4f}",
                    'PCtr': f"{avg_point_center:.4f}",
                    'Smooth': f"{avg_smooth:.4f}",
                    'Jump': f"{avg_jump:.4f}",
                    'Dir': f"{avg_dir_continuity:.4f}",
                    'Acc': f"{avg_acceleration:.4f}",
                })

        # å¹³å‡è®­ç»ƒæŒ‡æ ‡
        num_batches = len(train_loader)
        epoch_loss /= num_batches
        epoch_position_error /= num_batches

        # æ‰“å°è®­ç»ƒç»“æœ
        print(f"\nè®­ç»ƒç»“æœ:")
        print(f"  Loss: {epoch_loss:.4f}")
        print(f"  PositionError: {epoch_position_error:.4f}")

        # éªŒè¯
        if epoch % config.val_interval == 0:
            print(f"\néªŒè¯...")
            model.eval()
            val_loss = 0
            val_position_error = 0

            val_bar = tqdm(test_loader, desc="éªŒè¯")
            with torch.no_grad():
                for batch in val_bar:
                    images = batch['image'].to(config.device)
                    true_scanpaths = batch['scanpath'].to(config.device)

                    # å‰å‘ä¼ æ’­ - éªŒè¯æ¨¡å¼
                    # è®­ç»ƒç›®æ ‡ï¼šéªŒè¯æ¨¡å‹åœ¨æ¨ç†æ—¶çš„çœŸå®æ€§èƒ½
                    # ç­–ç•¥ï¼šä¸è®­ç»ƒé˜¶æ®µå¯¹é½çš„Teacher Forcingï¼Œé¿å…åˆ†å¸ƒå·®å¼‚è¿‡å¤§
                    # æ˜¾å¼è®¾ç½®enable_early_stop=Falseï¼Œç¡®ä¿è¿”å›3ä¸ªå€¼
                    if epoch <= 80:
                        val_teacher_forcing = 0.3  # é˜¶æ®µ1ï¼šè¾ƒé«˜Teacher Forcing
                    elif epoch <= 150:
                        val_teacher_forcing = 0.2  # é˜¶æ®µ2ï¼šä¸­ç­‰Teacher Forcing
                    else:
                        val_teacher_forcing = 0.1  # é˜¶æ®µ3ï¼šè¾ƒä½Teacher Forcing
                    result = model(images, gt_scanpaths=true_scanpaths, teacher_forcing_ratio=val_teacher_forcing, enable_early_stop=False)
                    # å®‰å…¨è§£åŒ…ï¼šæ— è®ºè¿”å›3ä¸ªè¿˜æ˜¯5ä¸ªå€¼ï¼Œéƒ½åªå–å‰3ä¸ª
                    predicted_scanpaths = result[0]
                    mus = result[1]
                    logvars = result[2]

                    # è®¡ç®—VAEæŸå¤±å‡½æ•°ï¼ˆä¸è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´ï¼‰
                    # 1. é‡æ„æŸå¤±ï¼ˆç”¨äºç›‘æ§ï¼‰
                    reconstruction_loss = nn.functional.mse_loss(predicted_scanpaths, true_scanpaths)

                    # 2. KLæ•£åº¦æ­£åˆ™åŒ–
                    kl_loss = -0.5 * torch.sum(1 + logvars - mus.pow(2) - logvars.exp())
                    kl_loss = kl_loss / (mus.size(0) * mus.size(1))

                    # 3. Beta-VAEæƒé‡ï¼ˆä¸è®­ç»ƒæ—¶ç›¸åŒï¼‰
                    beta = min(0.01, 0.005 * (1.01 ** (epoch - 1)))

                    # 4. è¦†ç›–èŒƒå›´æŸå¤±ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼Œä½¿ç”¨æ”¹è¿›åçš„ç‰ˆæœ¬ï¼‰
                    pred_min = predicted_scanpaths.min(dim=1)[0]
                    pred_max = predicted_scanpaths.max(dim=1)[0]
                    pred_range = pred_max - pred_min
                    coverage_loss = torch.mean(((0.5 - pred_range).clamp(min=0.0)) ** 2) * 2.0
                    
                    # 5. ä½ç½®å¤šæ ·æ€§æŸå¤±ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼Œä½¿ç”¨æ”¹è¿›åçš„ç‰ˆæœ¬ï¼‰
                    pred_mean = predicted_scanpaths.mean(dim=1)
                    pred_var = ((predicted_scanpaths - pred_mean.unsqueeze(1)) ** 2).mean(dim=1)
                    min_var = 0.03
                    diversity_loss = torch.mean(((min_var - pred_var).clamp(min=0.0)) ** 2) * 3.0
                    
                    # 6. ä¸­å¿ƒèšé›†æƒ©ç½šï¼ˆä¸è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´ï¼Œä½¿ç”¨æ”¹è¿›åçš„ç‰ˆæœ¬ï¼‰
                    mean_center_dist = torch.mean((pred_mean - 0.5) ** 2, dim=-1)
                    close_to_center = (mean_center_dist < 0.03).float()
                    medium_distance = ((mean_center_dist >= 0.03) & (mean_center_dist < 0.06)).float()
                    strong_penalty = torch.mean(close_to_center * (0.03 - mean_center_dist) * 200.0)
                    medium_penalty = torch.mean(medium_distance * (0.06 - mean_center_dist) * 50.0)
                    center_penalty = strong_penalty + medium_penalty
                    
                    point_center_dist = torch.mean((predicted_scanpaths - 0.5) ** 2, dim=-1)
                    point_center_penalty = torch.mean(((0.03 - point_center_dist).clamp(min=0.0)) ** 2) * 100.0
                    
                    # 7. è½¨è¿¹å¹³æ»‘æ€§æŸå¤±ï¼ˆä¸è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´ï¼ŒåŒ…æ‹¬æ–°å¢çš„åŠ é€Ÿåº¦å’Œæ–¹å‘è¿ç»­æ€§ï¼‰
                    pred_diffs = predicted_scanpaths[:, 1:] - predicted_scanpaths[:, :-1]
                    true_diffs = true_scanpaths[:, 1:] - true_scanpaths[:, :-1]
                    pred_step_lengths = torch.norm(pred_diffs, p=2, dim=-1)
                    true_step_lengths = torch.norm(true_diffs, p=2, dim=-1)
                    step_length_loss = nn.functional.mse_loss(pred_step_lengths, true_step_lengths)
                    large_jumps = (pred_step_lengths - 0.20).clamp(min=0.0)
                    jump_penalty = torch.mean(large_jumps ** 2)
                    
                    if pred_diffs.shape[1] > 1:
                        pred_directions = pred_diffs / (pred_step_lengths.unsqueeze(-1) + 1e-8)
                        true_directions = true_diffs / (true_step_lengths.unsqueeze(-1) + 1e-8)
                        pred_dir_diffs = pred_directions[:, 1:] - pred_directions[:, :-1]
                        true_dir_diffs = true_directions[:, 1:] - true_directions[:, :-1]
                        direction_loss = nn.functional.mse_loss(
                            torch.norm(pred_dir_diffs, p=2, dim=-1),
                            torch.norm(true_dir_diffs, p=2, dim=-1)
                        )
                    else:
                        direction_loss = torch.tensor(0.0, device=predicted_scanpaths.device)
                    
                    # åŠ é€Ÿåº¦çº¦æŸï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
                    if pred_step_lengths.shape[1] > 1:
                        pred_acceleration = pred_step_lengths[:, 1:] - pred_step_lengths[:, :-1]
                        true_acceleration = true_step_lengths[:, 1:] - true_step_lengths[:, :-1]
                        acceleration_loss = nn.functional.mse_loss(pred_acceleration, true_acceleration)
                    else:
                        acceleration_loss = torch.tensor(0.0, device=predicted_scanpaths.device)
                    
                    # æ–¹å‘è¿ç»­æ€§ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
                    if pred_directions.shape[1] > 0:
                        pred_dir_similarity = F.cosine_similarity(
                            pred_directions[:, :-1], 
                            pred_directions[:, 1:], 
                            dim=-1
                        )
                        true_dir_similarity = F.cosine_similarity(
                            true_directions[:, :-1], 
                            true_directions[:, 1:], 
                            dim=-1
                        )
                        direction_continuity_loss = nn.functional.mse_loss(
                            pred_dir_similarity, 
                            true_dir_similarity
                        )
                    else:
                        direction_continuity_loss = torch.tensor(0.0, device=predicted_scanpaths.device)
                    
                    # 8. Batchå†…å¤šæ ·æ€§æŸå¤±ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼Œä½¿ç”¨æ”¹è¿›åçš„ç‰ˆæœ¬ï¼‰
                    batch_mean = predicted_scanpaths.mean(dim=0, keepdim=True)
                    batch_diversity = torch.mean((predicted_scanpaths - batch_mean) ** 2)
                    min_batch_diversity = 0.015
                    batch_diversity_loss = torch.mean(((min_batch_diversity - batch_diversity).clamp(min=0.0)) ** 2)
                    
                    # 9. åŠ æƒMSEæŸå¤±ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼Œåˆ†é˜¶æ®µï¼‰
                    position_weights = torch.ones(config.seq_len, device=predicted_scanpaths.device)
                    if epoch <= 80:
                        position_weights[0] = 3.0
                        position_weights[1:5] = 2.0
                        position_weights[5:10] = 1.5
                    else:
                        position_weights[0] = 2.0
                        position_weights[1:5] = 1.5
                        position_weights[5:10] = 1.2
                    weighted_reconstruction_loss = torch.mean(
                        position_weights.unsqueeze(0).unsqueeze(-1) * 
                        (predicted_scanpaths - true_scanpaths) ** 2
                    )

                    # æ€»æŸå¤±ï¼ˆä¸è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´ï¼Œä½¿ç”¨æ”¹è¿›åçš„ç‰ˆæœ¬ï¼‰
                    if epoch <= 80:
                        coverage_weight = 0.15
                        diversity_weight = 0.1
                        center_weight = 0.2
                        point_center_weight = 0.15
                        smoothness_weight = 0.25
                        jump_weight = 0.1
                        direction_weight = 0.1
                        acceleration_weight = 0.1
                        direction_continuity_weight = 0.1
                        batch_diversity_weight = 0.05
                    elif epoch <= 150:
                        progress = (epoch - 80) / 70.0
                        coverage_weight = 0.15 + 0.05 * progress  # ä»0.15å¢åŠ åˆ°0.2
                        diversity_weight = 0.1 + 0.05 * progress  # ä»0.1å¢åŠ åˆ°0.15
                        center_weight = 0.2 + 0.05 * progress  # ä»0.2å¢åŠ åˆ°0.25
                        point_center_weight = 0.15 + 0.05 * progress  # ä»0.15å¢åŠ åˆ°0.2
                        smoothness_weight = 0.25 + 0.1 * progress
                        jump_weight = 0.1 + 0.05 * progress
                        direction_weight = 0.1 + 0.05 * progress
                        acceleration_weight = 0.1 + 0.05 * progress
                        direction_continuity_weight = 0.1 + 0.05 * progress
                        batch_diversity_weight = 0.05 + 0.05 * progress  # ä»0.05å¢åŠ åˆ°0.1
                    else:
                        coverage_weight = 0.2
                        diversity_weight = 0.15
                        center_weight = 0.25
                        point_center_weight = 0.2
                        smoothness_weight = 0.35
                        jump_weight = 0.15
                        direction_weight = 0.15
                        acceleration_weight = 0.15
                        direction_continuity_weight = 0.15
                        batch_diversity_weight = 0.1
                    
                    loss = weighted_reconstruction_loss + beta * kl_loss + \
                           coverage_weight * coverage_loss + \
                           diversity_weight * diversity_loss + \
                           center_weight * center_penalty + \
                           point_center_weight * point_center_penalty + \
                           smoothness_weight * step_length_loss + \
                           jump_weight * jump_penalty + \
                           direction_weight * direction_loss + \
                           acceleration_weight * acceleration_loss + \
                           direction_continuity_weight * direction_continuity_loss + \
                           batch_diversity_weight * batch_diversity_loss

                    # è®¡ç®—ä½ç½®è¯¯å·®ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼Œä½¿ç”¨åŠ æƒè¯¯å·®ï¼Œåˆ†é˜¶æ®µï¼‰
                    position_weights_error = torch.ones(config.seq_len, device=predicted_scanpaths.device)
                    if epoch <= 80:
                        position_weights_error[0] = 3.0  # ä¸è®­ç»ƒæ—¶ä¸€è‡´
                        position_weights_error[1:5] = 2.0
                        position_weights_error[5:10] = 1.5
                    else:
                        position_weights_error[0] = 2.0
                        position_weights_error[1:5] = 1.5
                        position_weights_error[5:10] = 1.2
                    
                    weighted_errors = torch.norm(
                        predicted_scanpaths - true_scanpaths,
                        dim=-1
                    ) * position_weights_error.unsqueeze(0)
                    position_error = weighted_errors.mean() / position_weights_error.mean()

                    val_loss += loss.item()
                    val_position_error += position_error.item()

            # å¹³å‡éªŒè¯æŒ‡æ ‡
            num_val_batches = len(test_loader)
            val_loss /= num_val_batches
            val_position_error /= num_val_batches

            print(f"\néªŒè¯ç»“æœ:")
            print(f"  Loss: {val_loss:.4f}")
            print(f"  PositionError: {val_position_error:.4f}")

            # å­¦ä¹ ç‡è°ƒåº¦ - ExponentialLRåœ¨æ¯ä¸ªepochåè‡ªåŠ¨è¡°å‡
            current_lr = optimizer.param_groups[0]['lr']
            print(f"  Learning Rate: {current_lr:.6f}")

            # ä¿å­˜æœ€ä½³æ¨¡å‹ï¼šä¼˜å…ˆåŸºäºä½ç½®è¯¯å·®ï¼Œä¹Ÿè€ƒè™‘æŸå¤±
            save_model = False
            if val_position_error < best_val_position_error:
                best_val_position_error = val_position_error
                save_model = True
                patience_counter = 0  # é‡ç½®æ—©åœè®¡æ•°å™¨ï¼ˆåŸºäºä½ç½®è¯¯å·®ï¼‰
                print(f"  âœ… éªŒè¯ä½ç½®è¯¯å·®æ”¹å–„: {val_position_error:.4f} (æ–°æœ€ä½³)")
            
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                if not save_model:  # å¦‚æœä½ç½®è¯¯å·®æ²¡æ”¹å–„ä½†æŸå¤±æ”¹å–„äº†ï¼Œä¹Ÿä¿å­˜
                    save_model = True
            
            if save_model:
                best_path = os.path.join(config.checkpoint_dir, 'best_model.pth')
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'best_loss': best_val_loss,
                    'best_position_error': best_val_position_error,
                }, best_path)
                print(f"  ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹: {best_path}")
                print(f"     æœ€ä½³éªŒè¯ä½ç½®è¯¯å·®: {best_val_position_error:.4f}")
                print(f"     æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.4f}")
            else:
                patience_counter += 1
                print(f"  âš ï¸ éªŒè¯ä½ç½®è¯¯å·®æœªæ”¹å–„ ({patience_counter}/{early_stopping_patience})")
                print(f"     å½“å‰: {val_position_error:.4f}, æœ€ä½³: {best_val_position_error:.4f}")

            # æ—©åœæ£€æŸ¥ï¼šåŸºäºä½ç½®è¯¯å·®
            if patience_counter >= early_stopping_patience:
                print(f"\nâ¹ï¸ æ—©åœè§¦å‘ï¼éªŒè¯ä½ç½®è¯¯å·®å·²ç»{early_stopping_patience}ä¸ªepochæ²¡æœ‰æ”¹å–„")
                print(f"æœ€ä½³éªŒè¯ä½ç½®è¯¯å·®: {best_val_position_error:.4f}")
                print(f"æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.4f}")
                break

        # ä¿å­˜æ£€æŸ¥ç‚¹
        if epoch % config.save_interval == 0:
            checkpoint_path = os.path.join(
                config.checkpoint_dir,
                f'checkpoint_epoch_{epoch}.pth'
            )
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
            }, checkpoint_path)
            print(f"  ä¿å­˜æ£€æŸ¥ç‚¹: {checkpoint_path}")

        # è·å–å½“å‰å­¦ä¹ ç‡
        current_lr = optimizer.param_groups[0]['lr']

        # è®°å½•æ—¥å¿—
        epoch_log = {
            'epoch': epoch,
            'learning_rate': current_lr,
            'train': {
                'loss': epoch_loss,
                'position_error': epoch_position_error,
            },
        }
        if epoch % config.val_interval == 0:
            epoch_log['val'] = {
                'loss': val_loss,
                'position_error': val_position_error,
            }

        training_log['epochs'].append(epoch_log)

        # ä¿å­˜è®­ç»ƒæ—¥å¿—
        log_path = os.path.join(config.log_dir, 'training_log.json')
        with open(log_path, 'w') as f:
            json.dump(training_log, f, indent=2)

        # å­¦ä¹ ç‡è¡°å‡ï¼ˆæ¯ä¸ªepochç»“æŸåï¼‰
        scheduler.step()

    print("\nè®­ç»ƒå®Œæˆï¼")
    print(f"æœ€ä½³éªŒè¯æŸå¤±: {best_loss:.4f}")
    print(f"\nä¸‹ä¸€æ­¥ï¼šä½¿ç”¨ visualize_mamba_agent.py å¯è§†åŒ–ç»“æœ")


if __name__ == '__main__':
    train()
