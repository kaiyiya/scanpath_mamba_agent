"""
Mamba-Adaptiveæ‰«æè·¯å¾„æ¨¡å‹è®­ç»ƒè„šæœ¬
ç»“åˆ Mamba + AdaptiveNN Focusæœºåˆ¶
"""
import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import json
from datetime import datetime
from tqdm import tqdm
from pathlib import Path

from config_mamba_adaptive import MambaAdaptiveConfig
from data.dataset import create_dataloaders
from models.mamba_adaptive_scanpath import MambaAdaptiveScanpath


def train():
    """è®­ç»ƒä¸»å‡½æ•°"""
    config = MambaAdaptiveConfig()

    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(config.log_dir, exist_ok=True)
    os.makedirs(config.checkpoint_dir, exist_ok=True)

    # åŠ è½½æ•°æ®
    print("åŠ è½½æ•°æ®...")
    train_loader, test_loader = create_dataloaders(config)
    print(f"è®­ç»ƒé›†: {len(train_loader)} batches")
    print(f"æµ‹è¯•é›†: {len(test_loader)} batches")

    # åˆ›å»ºæ¨¡å‹
    print("\nåˆ›å»ºMamba-Adaptiveæ¨¡å‹ï¼ˆç»“åˆFocusæœºåˆ¶ï¼‰...")
    model = MambaAdaptiveScanpath(config).to(config.device)
    print(f"æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters()) / 1e6:.2f}M")

    # ä¼˜åŒ–å™¨
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=config.learning_rate,
        weight_decay=config.weight_decay
    )

    # å­¦ä¹ ç‡è°ƒåº¦å™¨ - ä½¿ç”¨ä½™å¼¦é€€ç«ï¼ˆæ›´å¥½çš„æ”¶æ•›æ€§ï¼‰
    # è®­ç»ƒç›®æ ‡ï¼šå­¦ä¹ ç‡åœ¨å‰åŠç¨‹è¾ƒé«˜ï¼ˆå¿«é€Ÿå­¦ä¹ ï¼‰ï¼ŒååŠç¨‹è¾ƒä½ï¼ˆç²¾ç»†è°ƒä¼˜ï¼‰
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer,
        T_max=config.num_epochs,
        eta_min=config.learning_rate * 0.01  # æœ€å°å­¦ä¹ ç‡ä¸ºåˆå§‹çš„1%
    )

    # æ—©åœæœºåˆ¶ï¼šåŸºäºéªŒè¯ä½ç½®è¯¯å·®è€Œä¸æ˜¯æŸå¤±
    # æ”¹è¿›ï¼šä½¿ç”¨ä½ç½®è¯¯å·®ä½œä¸ºæ—©åœæŒ‡æ ‡ï¼Œæ›´ç¬¦åˆä¸»è¦ç›®æ ‡
    best_val_position_error = float('inf')
    patience_counter = 0
    early_stopping_patience = 20  # å¢åŠ åˆ°20ï¼Œç»™æ¨¡å‹æ›´å¤šæœºä¼š
    best_val_loss = float('inf')  # ä»ç„¶è®°å½•ï¼Œä½†ç”¨äºä¿å­˜æ¨¡å‹

    # è®­ç»ƒæ—¥å¿—
    training_log = {
        'config': {
            'seq_len': config.seq_len,
            'batch_size': config.batch_size,
            'learning_rate': config.learning_rate,
            'num_epochs': config.num_epochs,
            'feature_dim': config.feature_dim,
            'd_state': config.d_state,
            'focus_patch_size': config.focus_patch_size,
        },
        'epochs': []
    }

    # è®­ç»ƒå¾ªç¯
    print("\nå¼€å§‹è®­ç»ƒ...")
    best_loss = float('inf')

    for epoch in range(1, config.num_epochs + 1):
        print(f"\n{'='*80}")
        print(f"Epoch {epoch}/{config.num_epochs}")
        print(f"{'='*80}")

        # è®­ç»ƒ
        model.train()
        epoch_loss = 0
        epoch_position_error = 0

        train_bar = tqdm(train_loader, desc="è®­ç»ƒ")
        for batch_idx, batch in enumerate(train_bar):
            images = batch['image'].to(config.device)
            true_scanpaths = batch['scanpath'].to(config.device)

            # å‰å‘ä¼ æ’­ - ä¼ é€’çœŸå®ä½ç½®ç”¨äºTeacher Forcing
            # æ”¹è¿›Teacher Forcingç­–ç•¥ï¼šé™ä½æ¯”ä¾‹ï¼Œå‡å°‘è®­ç»ƒå’Œæ¨ç†åˆ†å¸ƒå·®å¼‚
            # å…³é”®é—®é¢˜ï¼šä¹‹å‰0.8çš„Teacher Forcingå¤ªé«˜ï¼Œå¯¼è‡´è®­ç»ƒå’Œæ¨ç†åˆ†å¸ƒå·®å¼‚å¤§
            # æ”¹è¿›ï¼šä½¿ç”¨æ›´ä½çš„Teacher Forcingï¼Œè®©æ¨¡å‹æ›´å¤šä¾èµ–è‡ªèº«é¢„æµ‹
            if epoch <= 50:
                teacher_forcing_ratio = 0.5  # é˜¶æ®µ1ï¼šä¸­ç­‰Teacher Forcingï¼ˆä»0.8é™åˆ°0.5ï¼‰
            elif epoch <= 100:
                # é˜¶æ®µ2ï¼šä»0.5é€æ¸é™åˆ°0.3
                progress = (epoch - 50) / 50.0
                teacher_forcing_ratio = 0.5 - 0.2 * progress
            else:
                # é˜¶æ®µ3ï¼šä¿æŒ0.3ï¼Œæ›´æ¥è¿‘æ¨ç†æ—¶çš„0.0
                teacher_forcing_ratio = 0.3

            # è®­ç»ƒæ—¶æ˜¾å¼è®¾ç½®enable_early_stop=Falseï¼Œç¡®ä¿è¿”å›3ä¸ªå€¼
            predicted_scanpaths, mus, logvars = model(
                images,
                gt_scanpaths=true_scanpaths,
                teacher_forcing_ratio=teacher_forcing_ratio,
                enable_early_stop=False
            )

            # è®¡ç®—æŸå¤±å‡½æ•° - VAEæ¡†æ¶ï¼šé‡æ„æŸå¤± + KLæ•£åº¦æ­£åˆ™åŒ–
            # 1. é‡æ„æŸå¤±ï¼ˆå‡†ç¡®åŒ¹é…çœŸå®è·¯å¾„ï¼‰
            # ä½¿ç”¨æ ‡å‡†MSEï¼ˆç”¨äºç›‘æ§ï¼‰ï¼Œå®é™…æŸå¤±ä½¿ç”¨åŠ æƒMSEï¼ˆè§ä¸‹æ–¹ï¼‰
            reconstruction_loss = nn.functional.mse_loss(predicted_scanpaths, true_scanpaths)

            # 2. KLæ•£åº¦æ­£åˆ™åŒ–ï¼ˆé˜²æ­¢è¿‡æ‹Ÿåˆï¼‰
            # KL(q(z|x) || p(z)) = -0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)
            kl_loss = -0.5 * torch.sum(1 + logvars - mus.pow(2) - logvars.exp())
            kl_loss = kl_loss / (mus.size(0) * mus.size(1))  # å½’ä¸€åŒ–

            # 3. Beta-VAEï¼šæ§åˆ¶KLæ•£åº¦çš„æƒé‡
            # è®­ç»ƒç›®æ ‡ï¼šä¿æŒVAEçš„éšæœºæ€§ï¼Œä½†ä¸å½±å“ä¸»è¦çš„ä½ç½®é¢„æµ‹ç²¾åº¦
            # ç­–ç•¥ï¼šä½¿ç”¨è¾ƒå°çš„betaå€¼ï¼Œè®©é‡æ„æŸå¤±å ä¸»å¯¼
            beta = min(0.01, 0.005 * (1.01 ** (epoch - 1)))  # ä»0.005å¼€å§‹ï¼Œæœ€å¤šåˆ°0.01

            # 4. è¦†ç›–èŒƒå›´æŸå¤±ï¼šé¼“åŠ±é¢„æµ‹è·¯å¾„è¦†ç›–æ•´ä¸ªå›¾åƒï¼Œé˜²æ­¢è¿‡åº¦èšé›†
            # è®¡ç®—é¢„æµ‹è·¯å¾„çš„è¦†ç›–èŒƒå›´ï¼ˆxå’Œyæ–¹å‘åˆ†åˆ«è®¡ç®—ï¼‰
            pred_min = predicted_scanpaths.min(dim=1)[0]  # (B, 2)
            pred_max = predicted_scanpaths.max(dim=1)[0]  # (B, 2)
            pred_range = pred_max - pred_min  # (B, 2)
            # æ”¹è¿›ï¼šä½¿ç”¨æ›´æ¸©å’Œçš„æƒ©ç½šï¼Œåªåœ¨è¦†ç›–èŒƒå›´éå¸¸å°æ—¶æ‰æƒ©ç½š
            # é˜ˆå€¼é™ä½åˆ°0.3ï¼Œæƒ©ç½šå¼ºåº¦é™ä½ï¼Œé¿å…è¿‡åº¦çº¦æŸ
            coverage_loss = torch.mean(((0.3 - pred_range).clamp(min=0.0)) ** 2) * 0.5  # é™ä½æƒ©ç½šå¼ºåº¦
            
            # 5. ä½ç½®å¤šæ ·æ€§æŸå¤±ï¼šé¼“åŠ±é¢„æµ‹ä½ç½®å…·æœ‰è¶³å¤Ÿçš„æ–¹å·®
            pred_mean = predicted_scanpaths.mean(dim=1)  # (B, 2)
            pred_var = ((predicted_scanpaths - pred_mean.unsqueeze(1)) ** 2).mean(dim=1)  # (B, 2)
            # æ”¹è¿›ï¼šé™ä½æ–¹å·®é˜ˆå€¼å’Œæƒ©ç½šå¼ºåº¦ï¼Œé¿å…è¿‡åº¦çº¦æŸ
            min_var = 0.015  # æœŸæœ›æœ€å°æ–¹å·®ï¼ˆå¯¹åº”æ ‡å‡†å·®çº¦0.12ï¼‰ï¼Œé™ä½é˜ˆå€¼
            diversity_loss = torch.mean(((min_var - pred_var).clamp(min=0.0)) ** 2) * 0.5  # å¤§å¹…é™ä½æƒ©ç½šå¼ºåº¦
            
            # 6. è¾¹ç•Œçº¦æŸï¼šé˜²æ­¢é¢„æµ‹è·‘åˆ°å›¾åƒè¾¹ç•Œå¤–ï¼ˆè¿™æ˜¯å…³é”®æ”¹è¿›ï¼ï¼‰
            # é—®é¢˜ï¼šé¢„æµ‹è·¯å¾„è·‘åˆ°è¾¹ç¼˜ï¼ˆx=0.9+, y=0.9+ï¼‰ï¼Œéœ€è¦çº¦æŸåœ¨åˆç†èŒƒå›´å†…
            # å®šä¹‰åˆç†èŒƒå›´ï¼š[0.05, 0.95]ï¼Œé¿å…è¾¹ç•Œæ•ˆåº”
            boundary_min = 0.05
            boundary_max = 0.95
            
            # æƒ©ç½šè¶…å‡ºè¾¹ç•Œçš„ä½ç½®
            below_boundary = (predicted_scanpaths < boundary_min).float()
            above_boundary = (predicted_scanpaths > boundary_max).float()
            boundary_penalty = torch.mean(
                below_boundary * (boundary_min - predicted_scanpaths) ** 2 +
                above_boundary * (predicted_scanpaths - boundary_max) ** 2
            ) * 10.0  # å¼ºæƒ©ç½šè¾¹ç•Œå¤–çš„ç‚¹
            
            # 7. æ¸©å’Œçš„ä¸­å¿ƒèšé›†æƒ©ç½šï¼šåªåœ¨éå¸¸æ¥è¿‘ä¸­å¿ƒæ—¶æ‰è½»å¾®æƒ©ç½š
            # æ”¹è¿›ï¼šå¤§å¹…é™ä½æƒ©ç½šå¼ºåº¦å’Œé˜ˆå€¼ï¼Œé¿å…è¿‡åº¦çº¦æŸ
            mean_center_dist = torch.mean((pred_mean - 0.5) ** 2, dim=-1)  # (B,)
            
            # åªåœ¨éå¸¸æ¥è¿‘ä¸­å¿ƒæ—¶ï¼ˆè·ç¦»<0.01ï¼Œå³å‡å€¼åœ¨[0.4, 0.6]ï¼‰æ‰è½»å¾®æƒ©ç½š
            very_close_to_center = (mean_center_dist < 0.01).float()
            center_penalty = torch.mean(very_close_to_center * (0.01 - mean_center_dist) * 5.0)  # å¤§å¹…é™ä½æƒ©ç½š
            
            # ç§»é™¤ç‚¹ä¸­å¿ƒæƒ©ç½šï¼Œé¿å…è¿‡åº¦çº¦æŸ
            point_center_penalty = torch.tensor(0.0, device=predicted_scanpaths.device)

            # 8. è½¨è¿¹å¹³æ»‘æ€§æŸå¤±ï¼šé¼“åŠ±ç›¸é‚»ç‚¹ä¹‹é—´çš„è·ç¦»åˆç†ï¼Œä½¿è·¯å¾„è¿è´¯æµç•…
            # è®¡ç®—ç›¸é‚»ç‚¹ä¹‹é—´çš„æ­¥é•¿
            pred_diffs = predicted_scanpaths[:, 1:] - predicted_scanpaths[:, :-1]  # (B, seq_len-1, 2)
            true_diffs = true_scanpaths[:, 1:] - true_scanpaths[:, :-1]  # (B, seq_len-1, 2)
            
            # æ­¥é•¿è·ç¦»
            pred_step_lengths = torch.norm(pred_diffs, p=2, dim=-1)  # (B, seq_len-1)
            true_step_lengths = torch.norm(true_diffs, p=2, dim=-1)  # (B, seq_len-1)
            
            # å¹³æ»‘æ€§æŸå¤±1ï¼šç›¸é‚»ç‚¹è·ç¦»åº”è¯¥ä¸çœŸå®è·¯å¾„ç›¸ä¼¼
            step_length_loss = nn.functional.mse_loss(pred_step_lengths, true_step_lengths)
            
            # å¹³æ»‘æ€§æŸå¤±2ï¼šæƒ©ç½šè¿‡å¤§çš„è·³è·ƒï¼ˆé˜²æ­¢è·¯å¾„è¿‡äºåˆ†æ•£ï¼‰
            # çœŸå®è·¯å¾„çš„æ­¥é•¿é€šå¸¸å°äº0.15ï¼Œæƒ©ç½šè¶…è¿‡0.2çš„è·³è·ƒ
            max_reasonable_step = 0.20
            large_jumps = (pred_step_lengths - max_reasonable_step).clamp(min=0.0)  # åªæƒ©ç½šå¤§äº0.2çš„
            jump_penalty = torch.mean(large_jumps ** 2)
            
            # å¹³æ»‘æ€§æŸå¤±3ï¼šæ–¹å‘ä¸€è‡´æ€§ï¼ˆç›¸é‚»æ–¹å‘å˜åŒ–ä¸åº”è¯¥å¤ªå¤§ï¼‰
            # è®¡ç®—æ–¹å‘å‘é‡
            pred_directions = pred_diffs / (pred_step_lengths.unsqueeze(-1) + 1e-8)  # å½’ä¸€åŒ–æ–¹å‘
            true_directions = true_diffs / (true_step_lengths.unsqueeze(-1) + 1e-8)
            
            # è®¡ç®—ç›¸é‚»æ–¹å‘çš„ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆåº”è¯¥æ˜¯æ­£çš„ï¼Œè¡¨ç¤ºæ–¹å‘å˜åŒ–å¹³ç¼“ï¼‰
            if pred_directions.shape[1] > 1:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„ç‚¹è®¡ç®—æ–¹å‘å˜åŒ–
                pred_dir_diffs = pred_directions[:, 1:] - pred_directions[:, :-1]  # æ–¹å‘å˜åŒ–
                true_dir_diffs = true_directions[:, 1:] - true_directions[:, :-1]
                direction_loss = nn.functional.mse_loss(
                    torch.norm(pred_dir_diffs, p=2, dim=-1),
                    torch.norm(true_dir_diffs, p=2, dim=-1)
                )
            else:
                direction_loss = torch.tensor(0.0, device=predicted_scanpaths.device)
            
            # å¹³æ»‘æ€§æŸå¤±4ï¼šåŠ é€Ÿåº¦çº¦æŸï¼ˆæ­¥é•¿çš„å˜åŒ–åº”è¯¥å¹³æ»‘ï¼Œä¿è¯è·¯å¾„æµç•…ï¼‰
            # è®¡ç®—åŠ é€Ÿåº¦ï¼šç›¸é‚»æ­¥é•¿ä¹‹é—´çš„å˜åŒ–
            if pred_step_lengths.shape[1] > 1:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ­¥é•¿è®¡ç®—åŠ é€Ÿåº¦
                pred_acceleration = pred_step_lengths[:, 1:] - pred_step_lengths[:, :-1]  # (B, seq_len-2)
                true_acceleration = true_step_lengths[:, 1:] - true_step_lengths[:, :-1]
                acceleration_loss = nn.functional.mse_loss(pred_acceleration, true_acceleration)
            else:
                acceleration_loss = torch.tensor(0.0, device=predicted_scanpaths.device)
            
            # å¹³æ»‘æ€§æŸå¤±5ï¼šæ–¹å‘è¿ç»­æ€§ï¼ˆç›¸é‚»æ–¹å‘åº”è¯¥ç›¸ä¼¼ï¼Œé¿å…çªç„¶è½¬å‘ï¼‰
            if pred_directions.shape[1] > 0:
                # è®¡ç®—ç›¸é‚»æ–¹å‘çš„ä½™å¼¦ç›¸ä¼¼åº¦
                pred_dir_similarity = F.cosine_similarity(
                    pred_directions[:, :-1], 
                    pred_directions[:, 1:], 
                    dim=-1
                )  # (B, seq_len-2)
                true_dir_similarity = F.cosine_similarity(
                    true_directions[:, :-1], 
                    true_directions[:, 1:], 
                    dim=-1
                )
                direction_continuity_loss = nn.functional.mse_loss(
                    pred_dir_similarity, 
                    true_dir_similarity
                )
            else:
                direction_continuity_loss = torch.tensor(0.0, device=predicted_scanpaths.device)

            # ========== åˆ†é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼šä½ç½®ç²¾åº¦ä¼˜å…ˆ ==========
            # æ ¸å¿ƒé—®é¢˜ï¼šæ­£åˆ™åŒ–æƒé‡è¿‡é«˜å¯¼è‡´Epoch 80åä½ç½®è¯¯å·®çªç„¶ä¸Šå‡
            # è§£å†³æ–¹æ¡ˆï¼šåˆ†é˜¶æ®µè®­ç»ƒï¼Œå…ˆä¼˜åŒ–ä½ç½®ç²¾åº¦ï¼Œå†è€ƒè™‘åˆ†æ•£æ€§
            
            # é˜¶æ®µ1 (Epoch 1-80): åªä¼˜åŒ–ä½ç½®ç²¾åº¦ï¼Œä¸åŠ å…¥å¼ºæ­£åˆ™åŒ–
            # é˜¶æ®µ2 (Epoch 81-150): é€æ¸åŠ å…¥è½»å¾®æ­£åˆ™åŒ–ï¼Œä½†æƒé‡å¾ˆå°
            # é˜¶æ®µ3 (Epoch 151+): å¦‚æœä½ç½®è¯¯å·®è¶³å¤Ÿä½ï¼Œé€‚å½“å¢åŠ æ­£åˆ™åŒ–
            
            if epoch <= 80:
                # é˜¶æ®µ1ï¼šé‡æ„æŸå¤±å ä¸»å¯¼ï¼ŒåªåŠ å…¥å¿…è¦çš„çº¦æŸ
                # æ”¹è¿›ï¼šå¤§å¹…é™ä½æ­£åˆ™åŒ–æƒé‡ï¼Œä¼˜å…ˆä¿è¯ä½ç½®ç²¾åº¦
                coverage_weight = 0.02  # å¤§å¹…é™ä½ï¼ˆä»0.15é™åˆ°0.02ï¼‰
                diversity_weight = 0.01  # å¤§å¹…é™ä½ï¼ˆä»0.1é™åˆ°0.01ï¼‰
                center_weight = 0.01  # å¤§å¹…é™ä½ï¼ˆä»0.2é™åˆ°0.01ï¼‰
                boundary_weight = 0.5  # è¾¹ç•Œçº¦æŸï¼šå¼ºçº¦æŸï¼Œé˜²æ­¢è·‘åˆ°è¾¹ç•Œå¤–
                point_center_weight = 0.0  # ç§»é™¤ç‚¹ä¸­å¿ƒæƒ©ç½š
                smoothness_weight = 0.15  # ä¿æŒå¹³æ»‘æ€§æƒé‡
                jump_weight = 0.05  # é™ä½è·³è·ƒæƒ©ç½š
                direction_weight = 0.05  # é™ä½æ–¹å‘ä¸€è‡´æ€§
            elif epoch <= 150:
                # é˜¶æ®µ2ï¼šé€æ¸å¢åŠ æ­£åˆ™åŒ–ï¼Œä½†ä¿æŒæ¸©å’Œ
                progress = (epoch - 80) / 70.0  # 0.0 -> 1.0
                coverage_weight = 0.02 + 0.03 * progress  # ä»0.02é€æ¸å¢åŠ åˆ°0.05
                diversity_weight = 0.01 + 0.02 * progress  # ä»0.01é€æ¸å¢åŠ åˆ°0.03
                center_weight = 0.01 + 0.02 * progress  # ä»0.01é€æ¸å¢åŠ åˆ°0.03
                boundary_weight = 0.5 - 0.2 * progress  # ä»0.5é€æ¸é™ä½åˆ°0.3ï¼ˆè¾¹ç•Œçº¦æŸé€æ¸æ”¾æ¾ï¼‰
                point_center_weight = 0.0  # ä¿æŒä¸º0
                smoothness_weight = 0.15 + 0.1 * progress  # ä»0.15å¢åŠ åˆ°0.25
                jump_weight = 0.05 + 0.05 * progress  # ä»0.05å¢åŠ åˆ°0.1
                direction_weight = 0.05 + 0.05 * progress  # ä»0.05å¢åŠ åˆ°0.1
                acceleration_weight = 0.05 + 0.05 * progress  # åŠ é€Ÿåº¦çº¦æŸï¼šä»0.05å¢åŠ åˆ°0.1
                direction_continuity_weight = 0.05 + 0.05 * progress  # æ–¹å‘è¿ç»­æ€§ï¼šä»0.05å¢åŠ åˆ°0.1
            else:
                # é˜¶æ®µ3ï¼šå¹³è¡¡ä¼˜åŒ–ï¼Œä¿æŒæ¸©å’Œçš„æ­£åˆ™åŒ–
                coverage_weight = 0.05  # ä¿æŒ0.05ï¼ˆä»0.15é™ä½ï¼‰
                diversity_weight = 0.03  # ä¿æŒ0.03ï¼ˆä»0.08é™ä½ï¼‰
                center_weight = 0.03  # ä¿æŒ0.03ï¼ˆä»0.15é™ä½ï¼‰
                boundary_weight = 0.3  # è¾¹ç•Œçº¦æŸï¼šä¿æŒ0.3
                point_center_weight = 0.0  # ä¿æŒä¸º0
                smoothness_weight = 0.25  # ä¿æŒ0.25ï¼ˆä»0.35é™ä½ï¼‰
                jump_weight = 0.1  # ä¿æŒ0.1ï¼ˆä»0.15é™ä½ï¼‰
                direction_weight = 0.1  # ä¿æŒ0.1ï¼ˆä»0.15é™ä½ï¼‰
                acceleration_weight = 0.1  # åŠ é€Ÿåº¦çº¦æŸ
                direction_continuity_weight = 0.1  # æ–¹å‘è¿ç»­æ€§
            
            # Batchå†…å¤šæ ·æ€§æŸå¤±ï¼šç§»é™¤æˆ–å¤§å¹…é™ä½æƒé‡
            batch_mean = predicted_scanpaths.mean(dim=0, keepdim=True)  # (1, seq_len, 2)
            batch_diversity = torch.mean((predicted_scanpaths - batch_mean) ** 2)  # æ ‡é‡
            min_batch_diversity = 0.01  # é™ä½é˜ˆå€¼
            batch_diversity_loss = torch.mean(((min_batch_diversity - batch_diversity).clamp(min=0.0)) ** 2)
            if epoch <= 80:
                batch_diversity_weight = 0.0  # é˜¶æ®µ1ä¸ä½¿ç”¨
            elif epoch <= 150:
                progress = (epoch - 80) / 70.0
                batch_diversity_weight = 0.01 * progress  # ä»0é€æ¸å¢åŠ åˆ°0.01
            else:
                batch_diversity_weight = 0.01  # é˜¶æ®µ3ä¿æŒ0.01ï¼ˆå¤§å¹…é™ä½ï¼‰
            
            # ä½¿ç”¨åŠ æƒMSEï¼šå¯¹èµ·å§‹ä½ç½®å’Œå‰å‡ æ­¥ç»™äºˆæ›´é«˜æƒé‡
            # ä¿®æ”¹ï¼šé™ä½æƒé‡ï¼Œé¿å…è¿‡åº¦å…³æ³¨å‰å‡ æ­¥è€Œå¿½ç•¥åç»­æ­¥éª¤
            position_weights = torch.ones(config.seq_len, device=predicted_scanpaths.device)
            if epoch <= 80:
                # é˜¶æ®µ1ï¼šé€‚åº¦æƒé‡ï¼Œå¹³è¡¡å‰åæ­¥éª¤
                position_weights[0] = 3.0  # èµ·å§‹ä½ç½®æƒé‡3å€ï¼ˆé™ä½ä»5.0ï¼‰
                position_weights[1:5] = 2.0  # å‰5æ­¥æƒé‡2å€ï¼ˆé™ä½ä»3.0ï¼‰
                position_weights[5:10] = 1.5  # 5-10æ­¥æƒé‡1.5å€ï¼ˆé™ä½ä»2.0ï¼‰
            else:
                # é˜¶æ®µ2å’Œ3ï¼šè¿›ä¸€æ­¥é™ä½æƒé‡ï¼Œæ›´å¹³è¡¡
                position_weights[0] = 2.0  # èµ·å§‹ä½ç½®æƒé‡2å€
                position_weights[1:5] = 1.5  # å‰5æ­¥æƒé‡1.5å€
                position_weights[5:10] = 1.2  # 5-10æ­¥æƒé‡1.2å€
            
            weighted_reconstruction_loss = torch.mean(
                position_weights.unsqueeze(0).unsqueeze(-1) * 
                (predicted_scanpaths - true_scanpaths) ** 2
            )
            
            # è®¡ç®—åŠ é€Ÿåº¦å’Œæ–¹å‘è¿ç»­æ€§æƒé‡ï¼ˆé˜¶æ®µ1ä¹Ÿéœ€è¦ï¼‰
            if epoch <= 80:
                acceleration_weight = 0.1  # é˜¶æ®µ1ï¼šåŠ é€Ÿåº¦çº¦æŸ
                direction_continuity_weight = 0.1  # é˜¶æ®µ1ï¼šæ–¹å‘è¿ç»­æ€§
            elif epoch <= 150:
                # å·²åœ¨ä¸Šé¢è®¡ç®—
                pass
            else:
                # å·²åœ¨ä¸Šé¢è®¡ç®—
                pass
            
            loss = weighted_reconstruction_loss + beta * kl_loss + \
                   coverage_weight * coverage_loss + \
                   diversity_weight * diversity_loss + \
                   center_weight * center_penalty + \
                   boundary_weight * boundary_penalty + \
                   point_center_weight * point_center_penalty + \
                   smoothness_weight * step_length_loss + \
                   jump_weight * jump_penalty + \
                   direction_weight * direction_loss + \
                   acceleration_weight * acceleration_loss + \
                   direction_continuity_weight * direction_continuity_loss + \
                   batch_diversity_weight * batch_diversity_loss

            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()

            # è®¡ç®—ä½ç½®è¯¯å·® - ä½¿ç”¨åŠ æƒè¯¯å·®ï¼ˆä¸æŸå¤±å‡½æ•°ä¸€è‡´ï¼Œæ›´å‡†ç¡®åœ°åæ˜ æ¨¡å‹æ€§èƒ½ï¼‰
            # è®­ç»ƒç›®æ ‡ï¼šä½ç½®è¯¯å·®åº”è¯¥ä¸æŸå¤±å‡½æ•°åŒæ­¥æ”¹å–„
            # æƒé‡ä¸æŸå¤±å‡½æ•°ä¸­çš„position_weightsä¿æŒä¸€è‡´
            position_weights_error = torch.ones(config.seq_len, device=predicted_scanpaths.device)
            if epoch <= 80:
                position_weights_error[0] = 3.0  # ä¸æŸå¤±å‡½æ•°ä¸€è‡´
                position_weights_error[1:5] = 2.0
                position_weights_error[5:10] = 1.5
            else:
                position_weights_error[0] = 2.0
                position_weights_error[1:5] = 1.5
                position_weights_error[5:10] = 1.2
            
            # åŠ æƒä½ç½®è¯¯å·®
            weighted_errors = torch.norm(
                predicted_scanpaths - true_scanpaths,
                dim=-1
            ) * position_weights_error.unsqueeze(0)
            position_error = weighted_errors.mean() / position_weights_error.mean()  # å½’ä¸€åŒ–ä»¥ä¿æŒåŸæœ‰å°ºåº¦

            # ç´¯ç§¯æŒ‡æ ‡
            epoch_loss += loss.item()
            epoch_position_error += position_error.item()

            # æ›´æ–°è¿›åº¦æ¡
            if (batch_idx + 1) % config.log_interval == 0:
                avg_loss = epoch_loss / (batch_idx + 1)
                avg_error = epoch_position_error / (batch_idx + 1)
                avg_coverage = coverage_loss.item()
                avg_diversity = diversity_loss.item()
                avg_center = center_penalty.item()
                avg_smooth = step_length_loss.item()
                avg_jump = jump_penalty.item()
                avg_batch_div = batch_diversity_loss.item()
                avg_point_center = point_center_penalty.item()
                avg_acceleration = acceleration_loss.item()
                avg_dir_continuity = direction_continuity_loss.item()
                train_bar.set_postfix({
                    'Loss': f"{avg_loss:.4f}",
                    'PosErr': f"{avg_error:.4f}",
                    'Beta': f"{beta:.4f}",
                    'Cov': f"{avg_coverage:.4f}",
                    'Ctr': f"{avg_center:.4f}",
                    'PCtr': f"{avg_point_center:.4f}",
                    'Smooth': f"{avg_smooth:.4f}",
                    'Jump': f"{avg_jump:.4f}",
                    'Dir': f"{avg_dir_continuity:.4f}",
                    'Acc': f"{avg_acceleration:.4f}",
                })

        # å¹³å‡è®­ç»ƒæŒ‡æ ‡
        num_batches = len(train_loader)
        epoch_loss /= num_batches
        epoch_position_error /= num_batches

        # æ‰“å°è®­ç»ƒç»“æœ
        print(f"\nè®­ç»ƒç»“æœ:")
        print(f"  Loss: {epoch_loss:.4f}")
        print(f"  PositionError: {epoch_position_error:.4f}")

        # éªŒè¯
        if epoch % config.val_interval == 0:
            print(f"\néªŒè¯...")
            model.eval()
            val_loss = 0
            val_position_error = 0

            val_bar = tqdm(test_loader, desc="éªŒè¯")
            with torch.no_grad():
                for batch in val_bar:
                    images = batch['image'].to(config.device)
                    true_scanpaths = batch['scanpath'].to(config.device)

                    # å‰å‘ä¼ æ’­ - éªŒè¯æ¨¡å¼
                    # è®­ç»ƒç›®æ ‡ï¼šéªŒè¯æ¨¡å‹åœ¨æ¨ç†æ—¶çš„çœŸå®æ€§èƒ½
                    # ç­–ç•¥ï¼šä½¿ç”¨æ›´ä½çš„Teacher Forcingï¼Œæ›´æ¥è¿‘æ¨ç†æ—¶çš„0.0
                    # æ˜¾å¼è®¾ç½®enable_early_stop=Falseï¼Œç¡®ä¿è¿”å›3ä¸ªå€¼
                    if epoch <= 50:
                        val_teacher_forcing = 0.2  # é˜¶æ®µ1ï¼šè¾ƒä½Teacher Forcingï¼ˆä»0.3é™åˆ°0.2ï¼‰
                    elif epoch <= 100:
                        val_teacher_forcing = 0.1  # é˜¶æ®µ2ï¼šæ›´ä½Teacher Forcingï¼ˆä»0.2é™åˆ°0.1ï¼‰
                    else:
                        val_teacher_forcing = 0.05  # é˜¶æ®µ3ï¼šéå¸¸ä½Teacher Forcingï¼ˆä»0.1é™åˆ°0.05ï¼‰
                    result = model(images, gt_scanpaths=true_scanpaths, teacher_forcing_ratio=val_teacher_forcing, enable_early_stop=False)
                    # å®‰å…¨è§£åŒ…ï¼šæ— è®ºè¿”å›3ä¸ªè¿˜æ˜¯5ä¸ªå€¼ï¼Œéƒ½åªå–å‰3ä¸ª
                    predicted_scanpaths = result[0]
                    mus = result[1]
                    logvars = result[2]

                    # è®¡ç®—VAEæŸå¤±å‡½æ•°ï¼ˆä¸è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´ï¼‰
                    # 1. é‡æ„æŸå¤±ï¼ˆç”¨äºç›‘æ§ï¼‰
                    reconstruction_loss = nn.functional.mse_loss(predicted_scanpaths, true_scanpaths)

                    # 2. KLæ•£åº¦æ­£åˆ™åŒ–
                    kl_loss = -0.5 * torch.sum(1 + logvars - mus.pow(2) - logvars.exp())
                    kl_loss = kl_loss / (mus.size(0) * mus.size(1))

                    # 3. Beta-VAEæƒé‡ï¼ˆä¸è®­ç»ƒæ—¶ç›¸åŒï¼‰
                    beta = min(0.01, 0.005 * (1.01 ** (epoch - 1)))

                    # 4. è¦†ç›–èŒƒå›´æŸå¤±ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼Œä½¿ç”¨æ”¹è¿›åçš„ç‰ˆæœ¬ï¼‰
                    pred_min = predicted_scanpaths.min(dim=1)[0]
                    pred_max = predicted_scanpaths.max(dim=1)[0]
                    pred_range = pred_max - pred_min
                    coverage_loss = torch.mean(((0.3 - pred_range).clamp(min=0.0)) ** 2) * 0.5
                    
                    # 5. ä½ç½®å¤šæ ·æ€§æŸå¤±ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼Œä½¿ç”¨æ”¹è¿›åçš„ç‰ˆæœ¬ï¼‰
                    pred_mean = predicted_scanpaths.mean(dim=1)
                    pred_var = ((predicted_scanpaths - pred_mean.unsqueeze(1)) ** 2).mean(dim=1)
                    min_var = 0.015
                    diversity_loss = torch.mean(((min_var - pred_var).clamp(min=0.0)) ** 2) * 0.5
                    
                    # 6. è¾¹ç•Œçº¦æŸï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
                    boundary_min = 0.05
                    boundary_max = 0.95
                    below_boundary = (predicted_scanpaths < boundary_min).float()
                    above_boundary = (predicted_scanpaths > boundary_max).float()
                    boundary_penalty = torch.mean(
                        below_boundary * (boundary_min - predicted_scanpaths) ** 2 +
                        above_boundary * (predicted_scanpaths - boundary_max) ** 2
                    ) * 10.0
                    
                    # 7. æ¸©å’Œçš„ä¸­å¿ƒèšé›†æƒ©ç½šï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
                    mean_center_dist = torch.mean((pred_mean - 0.5) ** 2, dim=-1)
                    very_close_to_center = (mean_center_dist < 0.01).float()
                    center_penalty = torch.mean(very_close_to_center * (0.01 - mean_center_dist) * 5.0)
                    point_center_penalty = torch.tensor(0.0, device=predicted_scanpaths.device)
                    
                    # 8. è½¨è¿¹å¹³æ»‘æ€§æŸå¤±ï¼ˆä¸è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´ï¼ŒåŒ…æ‹¬æ–°å¢çš„åŠ é€Ÿåº¦å’Œæ–¹å‘è¿ç»­æ€§ï¼‰
                    pred_diffs = predicted_scanpaths[:, 1:] - predicted_scanpaths[:, :-1]
                    true_diffs = true_scanpaths[:, 1:] - true_scanpaths[:, :-1]
                    pred_step_lengths = torch.norm(pred_diffs, p=2, dim=-1)
                    true_step_lengths = torch.norm(true_diffs, p=2, dim=-1)
                    step_length_loss = nn.functional.mse_loss(pred_step_lengths, true_step_lengths)
                    large_jumps = (pred_step_lengths - 0.20).clamp(min=0.0)
                    jump_penalty = torch.mean(large_jumps ** 2)
                    
                    if pred_diffs.shape[1] > 1:
                        pred_directions = pred_diffs / (pred_step_lengths.unsqueeze(-1) + 1e-8)
                        true_directions = true_diffs / (true_step_lengths.unsqueeze(-1) + 1e-8)
                        pred_dir_diffs = pred_directions[:, 1:] - pred_directions[:, :-1]
                        true_dir_diffs = true_directions[:, 1:] - true_directions[:, :-1]
                        direction_loss = nn.functional.mse_loss(
                            torch.norm(pred_dir_diffs, p=2, dim=-1),
                            torch.norm(true_dir_diffs, p=2, dim=-1)
                        )
                    else:
                        direction_loss = torch.tensor(0.0, device=predicted_scanpaths.device)
                    
                    # åŠ é€Ÿåº¦çº¦æŸï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
                    if pred_step_lengths.shape[1] > 1:
                        pred_acceleration = pred_step_lengths[:, 1:] - pred_step_lengths[:, :-1]
                        true_acceleration = true_step_lengths[:, 1:] - true_step_lengths[:, :-1]
                        acceleration_loss = nn.functional.mse_loss(pred_acceleration, true_acceleration)
                    else:
                        acceleration_loss = torch.tensor(0.0, device=predicted_scanpaths.device)
                    
                    # æ–¹å‘è¿ç»­æ€§ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
                    if pred_directions.shape[1] > 0:
                        pred_dir_similarity = F.cosine_similarity(
                            pred_directions[:, :-1], 
                            pred_directions[:, 1:], 
                            dim=-1
                        )
                        true_dir_similarity = F.cosine_similarity(
                            true_directions[:, :-1], 
                            true_directions[:, 1:], 
                            dim=-1
                        )
                        direction_continuity_loss = nn.functional.mse_loss(
                            pred_dir_similarity, 
                            true_dir_similarity
                        )
                    else:
                        direction_continuity_loss = torch.tensor(0.0, device=predicted_scanpaths.device)
                    
                    # 9. Batchå†…å¤šæ ·æ€§æŸå¤±ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼Œä½¿ç”¨æ”¹è¿›åçš„ç‰ˆæœ¬ï¼‰
                    batch_mean = predicted_scanpaths.mean(dim=0, keepdim=True)
                    batch_diversity = torch.mean((predicted_scanpaths - batch_mean) ** 2)
                    min_batch_diversity = 0.01
                    batch_diversity_loss = torch.mean(((min_batch_diversity - batch_diversity).clamp(min=0.0)) ** 2)
                    
                    # 9. åŠ æƒMSEæŸå¤±ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼Œåˆ†é˜¶æ®µï¼‰
                    position_weights = torch.ones(config.seq_len, device=predicted_scanpaths.device)
                    if epoch <= 80:
                        position_weights[0] = 3.0
                        position_weights[1:5] = 2.0
                        position_weights[5:10] = 1.5
                    else:
                        position_weights[0] = 2.0
                        position_weights[1:5] = 1.5
                        position_weights[5:10] = 1.2
                    weighted_reconstruction_loss = torch.mean(
                        position_weights.unsqueeze(0).unsqueeze(-1) * 
                        (predicted_scanpaths - true_scanpaths) ** 2
                    )

                    # æ€»æŸå¤±ï¼ˆä¸è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´ï¼Œä½¿ç”¨æ”¹è¿›åçš„ç‰ˆæœ¬ï¼‰
                    if epoch <= 80:
                        coverage_weight = 0.02
                        diversity_weight = 0.01
                        center_weight = 0.01
                        boundary_weight = 0.5
                        point_center_weight = 0.0
                        smoothness_weight = 0.15
                        jump_weight = 0.05
                        direction_weight = 0.05
                        acceleration_weight = 0.05
                        direction_continuity_weight = 0.05
                        batch_diversity_weight = 0.0
                    elif epoch <= 150:
                        progress = (epoch - 80) / 70.0
                        coverage_weight = 0.02 + 0.03 * progress  # ä»0.02å¢åŠ åˆ°0.05
                        diversity_weight = 0.01 + 0.02 * progress  # ä»0.01å¢åŠ åˆ°0.03
                        center_weight = 0.01 + 0.02 * progress  # ä»0.01å¢åŠ åˆ°0.03
                        boundary_weight = 0.5 - 0.2 * progress  # ä»0.5é™ä½åˆ°0.3
                        point_center_weight = 0.0
                        smoothness_weight = 0.15 + 0.1 * progress
                        jump_weight = 0.05 + 0.05 * progress
                        direction_weight = 0.05 + 0.05 * progress
                        acceleration_weight = 0.05 + 0.05 * progress
                        direction_continuity_weight = 0.05 + 0.05 * progress
                        batch_diversity_weight = 0.01 * progress  # ä»0å¢åŠ åˆ°0.01
                    else:
                        coverage_weight = 0.05
                        diversity_weight = 0.03
                        center_weight = 0.03
                        boundary_weight = 0.3
                        point_center_weight = 0.0
                        smoothness_weight = 0.25
                        jump_weight = 0.1
                        direction_weight = 0.1
                        acceleration_weight = 0.1
                        direction_continuity_weight = 0.1
                        batch_diversity_weight = 0.01
                    
                    loss = weighted_reconstruction_loss + beta * kl_loss + \
                           coverage_weight * coverage_loss + \
                           diversity_weight * diversity_loss + \
                           center_weight * center_penalty + \
                           boundary_weight * boundary_penalty + \
                           point_center_weight * point_center_penalty + \
                           smoothness_weight * step_length_loss + \
                           jump_weight * jump_penalty + \
                           direction_weight * direction_loss + \
                           acceleration_weight * acceleration_loss + \
                           direction_continuity_weight * direction_continuity_loss + \
                           batch_diversity_weight * batch_diversity_loss

                    # è®¡ç®—ä½ç½®è¯¯å·®ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼Œä½¿ç”¨åŠ æƒè¯¯å·®ï¼Œåˆ†é˜¶æ®µï¼‰
                    position_weights_error = torch.ones(config.seq_len, device=predicted_scanpaths.device)
                    if epoch <= 80:
                        position_weights_error[0] = 3.0  # ä¸è®­ç»ƒæ—¶ä¸€è‡´
                        position_weights_error[1:5] = 2.0
                        position_weights_error[5:10] = 1.5
                    else:
                        position_weights_error[0] = 2.0
                        position_weights_error[1:5] = 1.5
                        position_weights_error[5:10] = 1.2
                    
                    weighted_errors = torch.norm(
                        predicted_scanpaths - true_scanpaths,
                        dim=-1
                    ) * position_weights_error.unsqueeze(0)
                    position_error = weighted_errors.mean() / position_weights_error.mean()

                    val_loss += loss.item()
                    val_position_error += position_error.item()

            # å¹³å‡éªŒè¯æŒ‡æ ‡
            num_val_batches = len(test_loader)
            val_loss /= num_val_batches
            val_position_error /= num_val_batches

            print(f"\néªŒè¯ç»“æœ:")
            print(f"  Loss: {val_loss:.4f}")
            print(f"  PositionError: {val_position_error:.4f}")

            # å­¦ä¹ ç‡è°ƒåº¦ - ExponentialLRåœ¨æ¯ä¸ªepochåè‡ªåŠ¨è¡°å‡
            current_lr = optimizer.param_groups[0]['lr']
            print(f"  Learning Rate: {current_lr:.6f}")

            # ä¿å­˜æœ€ä½³æ¨¡å‹ï¼šä¼˜å…ˆåŸºäºä½ç½®è¯¯å·®ï¼Œä¹Ÿè€ƒè™‘æŸå¤±
            save_model = False
            if val_position_error < best_val_position_error:
                best_val_position_error = val_position_error
                save_model = True
                patience_counter = 0  # é‡ç½®æ—©åœè®¡æ•°å™¨ï¼ˆåŸºäºä½ç½®è¯¯å·®ï¼‰
                print(f"  âœ… éªŒè¯ä½ç½®è¯¯å·®æ”¹å–„: {val_position_error:.4f} (æ–°æœ€ä½³)")
            
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                if not save_model:  # å¦‚æœä½ç½®è¯¯å·®æ²¡æ”¹å–„ä½†æŸå¤±æ”¹å–„äº†ï¼Œä¹Ÿä¿å­˜
                    save_model = True
            
            if save_model:
                best_path = os.path.join(config.checkpoint_dir, 'best_model.pth')
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'best_loss': best_val_loss,
                    'best_position_error': best_val_position_error,
                }, best_path)
                print(f"  ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹: {best_path}")
                print(f"     æœ€ä½³éªŒè¯ä½ç½®è¯¯å·®: {best_val_position_error:.4f}")
                print(f"     æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.4f}")
            else:
                patience_counter += 1
                print(f"  âš ï¸ éªŒè¯ä½ç½®è¯¯å·®æœªæ”¹å–„ ({patience_counter}/{early_stopping_patience})")
                print(f"     å½“å‰: {val_position_error:.4f}, æœ€ä½³: {best_val_position_error:.4f}")

            # æ—©åœæ£€æŸ¥ï¼šåŸºäºä½ç½®è¯¯å·®
            if patience_counter >= early_stopping_patience:
                print(f"\nâ¹ï¸ æ—©åœè§¦å‘ï¼éªŒè¯ä½ç½®è¯¯å·®å·²ç»{early_stopping_patience}ä¸ªepochæ²¡æœ‰æ”¹å–„")
                print(f"æœ€ä½³éªŒè¯ä½ç½®è¯¯å·®: {best_val_position_error:.4f}")
                print(f"æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.4f}")
                break

        # ä¿å­˜æ£€æŸ¥ç‚¹
        if epoch % config.save_interval == 0:
            checkpoint_path = os.path.join(
                config.checkpoint_dir,
                f'checkpoint_epoch_{epoch}.pth'
            )
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
            }, checkpoint_path)
            print(f"  ä¿å­˜æ£€æŸ¥ç‚¹: {checkpoint_path}")

        # è·å–å½“å‰å­¦ä¹ ç‡
        current_lr = optimizer.param_groups[0]['lr']

        # è®°å½•æ—¥å¿—
        epoch_log = {
            'epoch': epoch,
            'learning_rate': current_lr,
            'train': {
                'loss': epoch_loss,
                'position_error': epoch_position_error,
            },
        }
        if epoch % config.val_interval == 0:
            epoch_log['val'] = {
                'loss': val_loss,
                'position_error': val_position_error,
            }

        training_log['epochs'].append(epoch_log)

        # ä¿å­˜è®­ç»ƒæ—¥å¿—
        log_path = os.path.join(config.log_dir, 'training_log.json')
        with open(log_path, 'w') as f:
            json.dump(training_log, f, indent=2)

        # å­¦ä¹ ç‡è¡°å‡ï¼ˆæ¯ä¸ªepochç»“æŸåï¼‰
        scheduler.step()

    print("\nè®­ç»ƒå®Œæˆï¼")
    print(f"æœ€ä½³éªŒè¯æŸå¤±: {best_loss:.4f}")
    print(f"\nä¸‹ä¸€æ­¥ï¼šä½¿ç”¨ visualize_mamba_agent.py å¯è§†åŒ–ç»“æœ")


if __name__ == '__main__':
    train()
